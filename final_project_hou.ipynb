{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w261 Final Project - Clickthrough Rate Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your team number (from the spreadsheet)]   \n",
    "[Your team names]   \n",
    "Summer 2019, section [Your section numbers>]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* __Section 1__ - Question Formulation\n",
    "* __Section 2__ - Algorithm Explanation\n",
    "* __Section 3__ - EDA & Challenges\n",
    "* __Section 4__ - Algorithm Implementation\n",
    "* __Section 5__ - Course Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 1__ - Question Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 2__ - Algorithm Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we justify the selection of a particular algorithm for our project?\n",
    "1. when data is sparse, FM and FFM work better (need to see if the data is sparse)\n",
    "2. how to justify the choice of FFM over neronets, and trees and other algorithm??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 3__ - EDA & Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we run EDA on the entire dataset or just the sample train data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import isnan\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data from bucket and write the parquet format of the file to bucket\n",
    "# train_data = spark.read.csv(\"gs://w261-bucket-hou/final-project/data/train.txt\", sep=\"\\t\")\n",
    "# train_data.write.format(\"parquet\").save(\"gs://w261-bucket-hou/final-project/data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the parquet file\n",
    "train_parquet = spark.read.parquet(\"gs://w261-bucket-hou/final-project/data/train.parquet\")\n",
    "oldColNames = train_parquet.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.38 GiB   gs://w261-bucket-hou/final-project/data/train.txt\n",
      "2.74 GiB    gs://w261-bucket-hou/final-project/data/train.parquet\n"
     ]
    }
   ],
   "source": [
    "!gsutil du -sh gs://w261-bucket-hou/final-project/data/train.txt\n",
    "!gsutil du -sh gs://w261-bucket-hou/final-project/data/train.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      " |-- _c28: string (nullable = true)\n",
      " |-- _c29: string (nullable = true)\n",
      " |-- _c30: string (nullable = true)\n",
      " |-- _c31: string (nullable = true)\n",
      " |-- _c32: string (nullable = true)\n",
      " |-- _c33: string (nullable = true)\n",
      " |-- _c34: string (nullable = true)\n",
      " |-- _c35: string (nullable = true)\n",
      " |-- _c36: string (nullable = true)\n",
      " |-- _c37: string (nullable = true)\n",
      " |-- _c38: string (nullable = true)\n",
      " |-- _c39: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename files and recast integer types on the first 13 features\n",
    "train_parquet = train_parquet.withColumn(\"label\", train_parquet[\"_c0\"])\n",
    "for colNum in range(1,14): \n",
    "    colName = \"_c\" + str(colNum)\n",
    "    train_parquet = train_parquet.withColumn(\"int_feature_\"+ str(colNum), train_parquet[colName].cast(types.IntegerType()))\n",
    "for colNum in range(14,40): \n",
    "    colName = \"_c\" + str(colNum)\n",
    "    train_parquet = train_parquet.withColumn(\"cate_feature_\"+ str(colNum-13), train_parquet[colName])\n",
    "    \n",
    "train_parquet = train_parquet.drop(*oldColNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- int_feature_1: integer (nullable = true)\n",
      " |-- int_feature_2: integer (nullable = true)\n",
      " |-- int_feature_3: integer (nullable = true)\n",
      " |-- int_feature_4: integer (nullable = true)\n",
      " |-- int_feature_5: integer (nullable = true)\n",
      " |-- int_feature_6: integer (nullable = true)\n",
      " |-- int_feature_7: integer (nullable = true)\n",
      " |-- int_feature_8: integer (nullable = true)\n",
      " |-- int_feature_9: integer (nullable = true)\n",
      " |-- int_feature_10: integer (nullable = true)\n",
      " |-- int_feature_11: integer (nullable = true)\n",
      " |-- int_feature_12: integer (nullable = true)\n",
      " |-- int_feature_13: integer (nullable = true)\n",
      " |-- cate_feature_1: string (nullable = true)\n",
      " |-- cate_feature_2: string (nullable = true)\n",
      " |-- cate_feature_3: string (nullable = true)\n",
      " |-- cate_feature_4: string (nullable = true)\n",
      " |-- cate_feature_5: string (nullable = true)\n",
      " |-- cate_feature_6: string (nullable = true)\n",
      " |-- cate_feature_7: string (nullable = true)\n",
      " |-- cate_feature_8: string (nullable = true)\n",
      " |-- cate_feature_9: string (nullable = true)\n",
      " |-- cate_feature_10: string (nullable = true)\n",
      " |-- cate_feature_11: string (nullable = true)\n",
      " |-- cate_feature_12: string (nullable = true)\n",
      " |-- cate_feature_13: string (nullable = true)\n",
      " |-- cate_feature_14: string (nullable = true)\n",
      " |-- cate_feature_15: string (nullable = true)\n",
      " |-- cate_feature_16: string (nullable = true)\n",
      " |-- cate_feature_17: string (nullable = true)\n",
      " |-- cate_feature_18: string (nullable = true)\n",
      " |-- cate_feature_19: string (nullable = true)\n",
      " |-- cate_feature_20: string (nullable = true)\n",
      " |-- cate_feature_21: string (nullable = true)\n",
      " |-- cate_feature_22: string (nullable = true)\n",
      " |-- cate_feature_23: string (nullable = true)\n",
      " |-- cate_feature_24: string (nullable = true)\n",
      " |-- cate_feature_25: string (nullable = true)\n",
      " |-- cate_feature_26: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#record feature names by feature type\n",
    "# intFieldNames = [colName for colName, dType in train_parquet.dtypes if dType == 'int']\n",
    "# cateFieldNames = [colName for colName, dType in train_parquet.dtypes if dType == 'string' and colName != 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "recCount = train_parquet.count() #get record count\n",
    "fieldCount = len(train_parquet.columns)-1 #get the count of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distinctValues = []\n",
    "nullValues = []\n",
    "for colName in train_parquet.schema.names:\n",
    "    distinctValues.append(train_parquet.select(colName).distinct().count())\n",
    "    nullValues.append(train_parquet.filter((train_parquet[colName] == \"\") | train_parquet[colName].isNull() | isnan(train_parquet[colName])).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Overview:\n",
      "\n",
      "Record Count: 45840617\n",
      "Field Count: 39\n",
      "Null Value Percentage: 14.2%\n",
      "====================================================================== \n",
      "\n",
      "Column Level Information:\n",
      "\n",
      "Field Name     | Distinct Count | Null Count     | Null Percent   \n",
      "----------------------------------------------------------------------\n",
      "label          | 2              | 0              | 0.0%           \n",
      "int_feature_1  | 649            | 20793556       | 45.4%          \n",
      "int_feature_2  | 9364           | 0              | 0.0%           \n",
      "int_feature_3  | 14746          | 9839447        | 21.5%          \n",
      "int_feature_4  | 490            | 9937369        | 21.7%          \n",
      "int_feature_5  | 476707         | 1183117        | 2.6%           \n",
      "int_feature_6  | 11618          | 10252328       | 22.4%          \n",
      "int_feature_7  | 4142           | 1982866        | 4.3%           \n",
      "int_feature_8  | 1373           | 22773          | 0.0%           \n",
      "int_feature_9  | 7275           | 1982866        | 4.3%           \n",
      "int_feature_10 | 13             | 20793556       | 45.4%          \n",
      "int_feature_11 | 169            | 1982866        | 4.3%           \n",
      "int_feature_12 | 407            | 35071652       | 76.5%          \n",
      "int_feature_13 | 1376           | 9937369        | 21.7%          \n",
      "cate_feature_1 | 1460           | 0              | 0.0%           \n",
      "cate_feature_2 | 583            | 0              | 0.0%           \n",
      "cate_feature_3 | 10131227       | 1559473        | 3.4%           \n",
      "cate_feature_4 | 2202608        | 1559473        | 3.4%           \n",
      "cate_feature_5 | 305            | 0              | 0.0%           \n",
      "cate_feature_6 | 24             | 5540625        | 12.1%          \n",
      "cate_feature_7 | 12517          | 0              | 0.0%           \n",
      "cate_feature_8 | 633            | 0              | 0.0%           \n",
      "cate_feature_9 | 3              | 0              | 0.0%           \n",
      "cate_feature_10| 93145          | 0              | 0.0%           \n",
      "cate_feature_11| 5683           | 0              | 0.0%           \n",
      "cate_feature_12| 8351593        | 1559473        | 3.4%           \n",
      "cate_feature_13| 3194           | 0              | 0.0%           \n",
      "cate_feature_14| 27             | 0              | 0.0%           \n",
      "cate_feature_15| 14992          | 0              | 0.0%           \n",
      "cate_feature_16| 5461306        | 1559473        | 3.4%           \n",
      "cate_feature_17| 10             | 0              | 0.0%           \n",
      "cate_feature_18| 5652           | 0              | 0.0%           \n",
      "cate_feature_19| 2173           | 20172858       | 44.0%          \n",
      "cate_feature_20| 4              | 20172858       | 44.0%          \n",
      "cate_feature_21| 7046547        | 1559473        | 3.4%           \n",
      "cate_feature_22| 18             | 34955073       | 76.3%          \n",
      "cate_feature_23| 15             | 0              | 0.0%           \n",
      "cate_feature_24| 286181         | 1559473        | 3.4%           \n",
      "cate_feature_25| 105            | 20172858       | 44.0%          \n",
      "cate_feature_26| 142572         | 20172858       | 44.0%          \n"
     ]
    }
   ],
   "source": [
    "print(\"Training Dataset Overview:\\n\")\n",
    "print(\"Record Count:\", recCount)\n",
    "print(\"Field Count:\", fieldCount)\n",
    "print(\"Null Value Percentage:\", str(round(float(sum(nullValues))/(recCount*fieldCount)*100,1)) + \"%\")\n",
    "\n",
    "print(\"=\"*70, \"\\n\")\n",
    "\n",
    "\n",
    "print(\"Column Level Information:\\n\")\n",
    "print('%-15s| %-15s| %-15s| %-15s' %('Field Name','Distinct Count', 'Null Count', 'Null Percent'))\n",
    "print('-'*70)\n",
    "for colName, distinctVal, nullVal in zip(train_parquet.schema.names, distinctValues, nullValues):\n",
    "    print('%-15s| %-15s| %-15s| %-15s' %(colName, distinctVal, nullVal, str(round(float(nullVal)/recCount*100,1)) + \"%\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callenges will be caused by dataset being very sparse:\n",
    "1. null values in the training data\n",
    "2. the zeros created by one-hot encoding of the categorical variables (too many distinct values for the categorical variables)\n",
    "\n",
    "Solutions:\n",
    "1. feature selections\n",
    "2. hashing categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 4__ - Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Section 5__ - Course Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}