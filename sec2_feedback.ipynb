{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 Feedback\n",
    "\n",
    "This notebook documents feedback on the work Connor did in Section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduce the toy example before the four model:\n",
    "\n",
    "I think it may be worth it to introduce the toy example below before the four models. I think it'll be easier for readers to understand when having the idea of what kind of data we have in mind when discussing about the four models and also use it to explain the differences in the approaches of the four models.\n",
    "\n",
    "<table>\n",
    "<th>Response</th>\n",
    "<th>Publisher</th>\n",
    "<th>Advertiser</th>\n",
    "<th>Gender</th>\n",
    "<tr><td>1</td><td>Netflix</td><td>Pepsi</td><td>Male</td></tr>\n",
    "<tr><td>0</td><td>Spotify</td><td>Pepsi</td><td>Male</td></tr>\n",
    "<tr><td>0</td><td>Facebook</td><td>Gatorade</td><td>Female</td></tr>\n",
    "<tr><td>1</td><td>Spotify</td><td>Coca-cola</td><td>Male</td></tr>\n",
    "<tr><td>1</td><td>Facebook</td><td>Coca-cola</td><td>Female</td></tr>\n",
    "<tr><td>0</td><td>Facebook</td><td>Pepsi</td><td>Female</td></tr>\n",
    "<tr><td>1</td><td>Netflix</td><td>Gatorade</td><td>Female</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Poly-2 section:\n",
    "\n",
    "This is also to make the explanation lucid.  \n",
    "You current have:\n",
    "\n",
    "> \"Unfortunately, this model does not handle sparse datasets well. If we have 0 impressions of the __advertiser Pepsi with the publisher Pandora__, the model prediction will be trivial as no weight was learned for this feature combination. The model is also susceptible to overfitting, as it generates unreliable predictions for feature combinations with a very small number of impressions.\"\n",
    "\n",
    "I think instead of __advertiser Pepsi with the publisher Pandora__ you can refer to your toy example and said we can't reliably estimate the weight for the conjuction of (Netflix and Coca-cola) or (Spotify and Getorade).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Facotorization Machine Section:\n",
    "\n",
    "You used Pepsi and Pandora again, but I would recommend that we use something that we have in the toy example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Optimization - Function from papers is different from Log-loss?????\n",
    "\n",
    "In this section, the formula below has some typos in paratheses.\n",
    "\n",
    "$$ LogLoss = - \\frac{1}{n} \\sum_{i=1}^n [y_i \\cdot log_e(\\hat{y_i} + (1-y_i) \\cdot log_e(1-\\hat{y_i}] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Toy example: FFM in action:\n",
    "In this section, I wonder if it'll be useful to show the one-hot-encoded data table since it's the one that will be used in the caculation, such as the one below:\n",
    "\n",
    "<table>\n",
    "<th>Response</th>\n",
    "<th>Netflix</th>\n",
    "<th>Spotify</th>\n",
    "<th>Facebook</th>\n",
    "<th>Pepsi</th>\n",
    "<th>Gatorade</th>\n",
    "<th>Coca-cola</th>\n",
    "<th>Male</th>\n",
    "<th>Female</th>\n",
    "<tr><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
    "<tr><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>\n",
    "<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td></tr>\n",
    "<tr><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td></tr>\n",
    "<tr><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td></tr>\n",
    "<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
    "<tr><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Toy example: FFM in action:\n",
    "\n",
    "Should we included the response in the following table so readers can quickly see which impression we need to use `CTR` vs `1-CTR` when calculating loss?\n",
    "\n",
    "<table>\n",
    "<th>Impression</th>\n",
    "<th>$s$</th>\n",
    "<th>Predicted CTR</th>\n",
    "<th>Correct?</th>\n",
    "<tr><td>(Netflix, Pepsi, Male)</td><td>-0.27</td><td>$\\approx 0.43$</td><td>No</td></tr>\n",
    "<tr><td>(Spotify, Pepsi, Male)</td><td>-0.55</td><td>$\\approx 0.37$</td><td>Yes</td></tr>\n",
    "*<tr><td>(Facebook, Gatoriade, Female)</td><td>-1.05</td><td>$\\approx 0.26$</td><td>Yes</td></tr>\n",
    "<tr><td>(Spotify, Coca-cola, Male)</td><td>-0.93</td><td>$\\approx 0.28$</td><td>No</td></tr>\n",
    "<tr><td>(Facebook, Coca-cola, Female)</td><td>0.05</td><td>$\\approx 0.51$</td><td>Yes</td></tr>\n",
    "<tr><td>(Facebook, Pepsi, Female)</td><td>-0.30</td><td>$\\approx 0.43$</td><td>Yes</td></tr>\n",
    "<tr><td>(Netflix, Gatorade, Female)</td><td>-0.93</td><td>$\\approx 0.28$</td><td>No</td></tr>\n",
    "<table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. The formula of the gradient for our model:\n",
    "I'm debating if we should include this since it was explored and discussed in HW4 when we worked on distributed linear regression. I have a feeling that the structure and content of our final project should mirror our homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Linear Terms:\n",
    "\n",
    "Should we also included the linear terms in our model since our current FFM only has the future interaction terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__========================================separator for content from previous update===================================__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function:\n",
    "\n",
    "This section shares my understanding of the following two formula and why I think they are the same. The two formula are:\n",
    "\n",
    "$$ LogLoss = - \\frac{1}{n} \\sum_{i=1}^n [y_i \\cdot log_e\\hat{y_i} + (1-y_i) \\cdot log_e(1-\\hat{y_i})],\\ where\\ \\hat{y_i} = \\phi(\\textbf{w},\\textbf{x})$$\n",
    "\n",
    "vs\n",
    "\n",
    "$$ Loss = \\frac{1}{n} \\sum_{i=1}^n log(1+exp(-\\bar{y_i}\\phi(\\textbf{w},\\textbf{x}_i))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two formula are acutually the same. It's just the $\\bar{y_i}$ in the loss function from the paper has to have this relationship with $y_i$, where  \n",
    "$$\\bar{y_i} = \n",
    "\\begin{cases}\n",
    "    1,\\ if\\ y_i=1\\\\\n",
    "    -1,\\ if\\ y_i=0\\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More detailed derivation:\n",
    "\n",
    "<img src=\"derivation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test in code using Connor's example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCTR(s):\n",
    "    \"\"\"calculate CTR using model output\"\"\"\n",
    "    return 1/(1+np.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoss(labels, ctr):\n",
    "    \"\"\"calculate loss using Log Loss\"\"\"\n",
    "    return -(labels * np.log(ctr)+(1-labels) * np.log(1-ctr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLossPaper(labels, s):\n",
    "    \"\"\"calculate loss using the formula from the paper\"\"\"\n",
    "    #map the labels, from y to yBar\n",
    "    modified_labels = np.where(labels == 0, -1, labels)\n",
    "    return np.log(1+np.exp(-modified_labels*s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually input data (copying Connor's example)\n",
    "s = np.asarray([-0.27,-0.55,-1.05,-0.93,0.05,-0.3,-0.93])\n",
    "labels = np.asarray([1,0,0,1,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate CTR and the two losses\n",
    "\n",
    "ctr = getCTR(s)\n",
    "loss = getLoss(labels, ctr)\n",
    "lossPaper = getLossPaper(labels, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output: [-0.27 -0.55 -1.05 -0.93  0.05 -0.3  -0.93]\n",
      "Label: [1 0 0 1 1 0 1]\n",
      "CTR: [0.4329071  0.36586441 0.2592251  0.28292471 0.5124974  0.42555748\n",
      " 0.28292471]\n",
      "====================\n",
      "Log Loss:\n",
      " [0.83723214 0.45549248 0.30005848 1.26257444 0.66845965 0.55435524\n",
      " 1.26257444]\n",
      "Loss using formula from the paper:\n",
      " [0.83723214 0.45549248 0.30005848 1.26257444 0.66845965 0.55435524\n",
      " 1.26257444]\n",
      "Means of the Losses 0.7629638392999175 0.7629638392999174\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Output:\", s)\n",
    "print(\"Label:\", labels)\n",
    "print(\"CTR:\", ctr)\n",
    "\n",
    "print(\"=\"*20)\n",
    "\n",
    "print(\"Log Loss:\\n\", loss)\n",
    "print(\"Loss using formula from the paper:\\n\", lossPaper)\n",
    "print(\"Means of the Losses\", np.mean(loss), np.mean(lossPaper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
