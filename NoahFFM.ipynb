{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hashlib import sha256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "app_name = \"final_project_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a small sample to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sample.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile sample.txt\n",
    "1\t10\tESPN\tNike\n",
    "1\t15\tESPN\tNike\n",
    "0\t2\tESPN\tGucci\n",
    "1\t10\tESPN\tAdidas\n",
    "1\t10\tESPN\tAdidas\n",
    "0\t3\tVogue\tNike\n",
    "1\t20\tVogue\tGucci\n",
    "0\t5\tVogue\tAdidas\n",
    "1\t50\tNBC\tNike\n",
    "0\t0\tNBC\tGucci\n",
    "0\t4\tNBC\tAdidas\n",
    "0\t4\tNBC\tAdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_RDD = sc.textFile('sample.txt')\n",
    "split_RDD = sample_RDD.map(lambda line: line.split('\\t')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+------+\n",
      "| _1| _2|   _3|    _4|\n",
      "+---+---+-----+------+\n",
      "|  1| 10| ESPN|  Nike|\n",
      "|  1| 15| ESPN|  Nike|\n",
      "|  0|  2| ESPN| Gucci|\n",
      "|  1| 10| ESPN|Adidas|\n",
      "|  1| 10| ESPN|Adidas|\n",
      "|  0|  3|Vogue|  Nike|\n",
      "|  1| 20|Vogue| Gucci|\n",
      "|  0|  5|Vogue|Adidas|\n",
      "|  1| 50|  NBC|  Nike|\n",
      "|  0|  0|  NBC| Gucci|\n",
      "|  0|  4|  NBC|Adidas|\n",
      "|  0|  4|  NBC|Adidas|\n",
      "+---+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df = split_RDD.toDF()\n",
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_hash(x, modulo=10**6):\n",
    "    \"\"\"\n",
    "    Now we create a function that can be used to hash the features in each observation in the RDD. \n",
    "    We replace the label with 1, -1 and we hash all other features using sha256 \n",
    "    and then we take modulo some power of 10. \n",
    "    \"\"\"\n",
    "\n",
    "    x[0] = 2*int(x[0]) - 1\n",
    "    for i, value in enumerate(x[1:], 1):\n",
    "        h = sha256(\"{i}-{val}\".format(i=i,val=value).encode('ascii'))\n",
    "        hashed_value = int(h.hexdigest(), base=16) \n",
    "        hashed_value_mod = hashed_value % modulo\n",
    "        x[i] = hashed_value_mod\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_hashed = split_RDD.map(lambda x: feature_hash(x, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 51, 91, 29],\n",
       " [1, 57, 91, 29],\n",
       " [-1, 77, 91, 43],\n",
       " [1, 51, 91, 36],\n",
       " [1, 51, 91, 36],\n",
       " [-1, 27, 34, 29],\n",
       " [1, 14, 34, 43],\n",
       " [-1, 37, 34, 36],\n",
       " [1, 68, 48, 29],\n",
       " [-1, 35, 48, 43],\n",
       " [-1, 22, 48, 36],\n",
       " [-1, 22, 48, 36]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hashed.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x):\n",
    "    total = 0\n",
    "    for i in range(len(x) - 1):\n",
    "        for j in range(i+1, len(x)):\n",
    "            total += np.dot(w_old[x[i], j, :], w_old[x[j], i, :])\n",
    "            \n",
    "    return total\n",
    "\n",
    "def kappa(y, features):\n",
    "    return -y/(1 + np.exp(phi(features)))\n",
    "\n",
    "def gradient_update(x):\n",
    "    y = x[0]\n",
    "    features = x[1:]\n",
    "    k = kappa(y, features)\n",
    "    for i in range(len(features) - 1):\n",
    "        for j in range(i+1, len(features)):\n",
    "            yield ((i, features[j]), (eta * w_old[features[i], j, :] + k * w_old[features[j], i, :], 1))\n",
    "            \n",
    "    for i in range(len(features) - 1):\n",
    "        for j in range(i+1, len(features)):\n",
    "            yield ((j, features[i]), (eta * w_old[features[j], i, :] + k * w_old[features[i], j, :], 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize first random model\n",
    "k = 3\n",
    "n_features = 100\n",
    "n_fields = 3\n",
    "np.random.seed(1)\n",
    "w_old = np.random.uniform(0, 1/np.sqrt(k), size=(n_features, n_fields, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 51, 91, 29]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hashed.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value is the sum of these three: 0.7205119162918825\n"
     ]
    }
   ],
   "source": [
    "wj0f1_wj1f0 = np.dot(w_old[51, 1, :], w_old[91, 0, :])\n",
    "wj0f2_wj2f0 = np.dot(w_old[51, 2, :], w_old[29, 0, :])\n",
    "wj1f2_wj2f1 = np.dot(w_old[91, 2, :], w_old[29, 1, :])\n",
    "total = wj0f1_wj1f0 + wj0f2_wj2f0 + wj1f2_wj2f1\n",
    "print(f\"Expected value is the sum of these three: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7205119162918825"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.1\n",
    "sc.broadcast(w_old)\n",
    "sc.broadcast(eta)\n",
    "sample_hashed.map(lambda x: phi(x[1:])).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 91), (array([-0.12366285, -0.11483603, -0.0005904 ]), 1)),\n",
       " ((0, 29), (array([-0.14425123, -0.08595692, -0.11650726]), 1)),\n",
       " ((1, 29), (array([-0.14187508, -0.04045859, -0.12342043]), 1)),\n",
       " ((1, 51), (array([ 0.01263734, -0.01019001, -0.14014146]), 1)),\n",
       " ((2, 51), (array([-0.00913235, -0.14203834, -0.01008046]), 1)),\n",
       " ((2, 91), (array([-0.02036593, -0.04850733,  0.02783382]), 1)),\n",
       " ((0, 91), (array([-0.07888543, -0.09708068, -0.0064921 ]), 1)),\n",
       " ((0, 29), (array([-0.07605339, -0.07037244, -0.07434009]), 1)),\n",
       " ((1, 29), (array([-0.11308775, -0.02971325, -0.10108303]), 1)),\n",
       " ((1, 57), (array([-0.04041297,  0.01255432, -0.07420504]), 1)),\n",
       " ((2, 57), (array([-0.10559504, -0.08354991, -0.05221481]), 1)),\n",
       " ((2, 91), (array([-0.00798085, -0.03667551,  0.02975374]), 1)),\n",
       " ((0, 91), (array([0.16600099, 0.19724459, 0.08519065]), 1)),\n",
       " ((0, 43), (array([0.11363218, 0.02008188, 0.12477961]), 1)),\n",
       " ((1, 43), (array([0.0665013 , 0.19016751, 0.06649315]), 1)),\n",
       " ((1, 77), (array([0.10455133, 0.22733912, 0.13001895]), 1)),\n",
       " ((2, 77), (array([0.0872919 , 0.0326786 , 0.09099687]), 1)),\n",
       " ((2, 91), (array([0.09124787, 0.1215883 , 0.0294145 ]), 1)),\n",
       " ((0, 91), (array([-0.14004996, -0.13096982, -0.00652831]), 1)),\n",
       " ((0, 36), (array([-0.09163043, -0.04461945, -0.01703134]), 1)),\n",
       " ((1, 36), (array([-0.11059167, -0.09502788, -0.13560267]), 1)),\n",
       " ((1, 51), (array([ 0.00919751, -0.01638338, -0.15933545]), 1)),\n",
       " ((2, 51), (array([-0.0361822 , -0.1811066 , -0.04781654]), 1)),\n",
       " ((2, 91), (array([-0.04309205, -0.04405494,  0.02552141]), 1)),\n",
       " ((0, 91), (array([-0.14004996, -0.13096982, -0.00652831]), 1)),\n",
       " ((0, 36), (array([-0.09163043, -0.04461945, -0.01703134]), 1)),\n",
       " ((1, 36), (array([-0.11059167, -0.09502788, -0.13560267]), 1)),\n",
       " ((1, 51), (array([ 0.00919751, -0.01638338, -0.15933545]), 1)),\n",
       " ((2, 51), (array([-0.0361822 , -0.1811066 , -0.04781654]), 1)),\n",
       " ((2, 91), (array([-0.04309205, -0.04405494,  0.02552141]), 1)),\n",
       " ((0, 34), (array([0.06527165, 0.06478549, 0.14590665]), 1)),\n",
       " ((0, 29), (array([0.20760218, 0.13599975, 0.1821006 ]), 1)),\n",
       " ((1, 29), (array([0.17052172, 0.06451128, 0.13193755]), 1)),\n",
       " ((1, 27), (array([0.0296366 , 0.08866191, 0.15649661]), 1)),\n",
       " ((2, 27), (array([0.21497821, 0.04366709, 0.21619888]), 1)),\n",
       " ((2, 34), (array([0.09621306, 0.0385995 , 0.07347708]), 1)),\n",
       " ((0, 34), (array([-0.0565203 , -0.01353922, -0.06871023]), 1)),\n",
       " ((0, 43), (array([-0.06377608, -0.01090379, -0.06078904]), 1)),\n",
       " ((1, 43), (array([-0.02976076, -0.16165822, -0.05143055]), 1)),\n",
       " ((1, 14), (array([-0.03882368, -0.11027615, -0.16983578]), 1)),\n",
       " ((2, 14), (array([-0.0916813 , -0.00063737, -0.1391282 ]), 1)),\n",
       " ((2, 34), (array([-0.04187117,  0.02277116, -0.02344119]), 1)),\n",
       " ((0, 34), (array([0.08645855, 0.09455672, 0.16503512]), 1)),\n",
       " ((0, 36), (array([0.13231105, 0.14366076, 0.08479511]), 1)),\n",
       " ((1, 36), (array([0.13685881, 0.11315083, 0.13949897]), 1)),\n",
       " ((1, 37), (array([0.08357662, 0.1842821 , 0.19996204]), 1)),\n",
       " ((2, 37), (array([0.13543866, 0.19759817, 0.19519042]), 1)),\n",
       " ((2, 34), (array([0.0863531 , 0.05316811, 0.0756308 ]), 1)),\n",
       " ((0, 48), (array([-0.02519503, -0.07162494, -0.12530187]), 1)),\n",
       " ((0, 29), (array([-0.12151208, -0.10546108, -0.110598  ]), 1)),\n",
       " ((1, 29), (array([-0.1027784 , -0.04778721, -0.0787095 ]), 1)),\n",
       " ((1, 68), (array([-1.38886514e-01,  1.03100416e-04,  1.18119212e-02]), 1)),\n",
       " ((2, 68), (array([-0.0239938 , -0.02535181,  0.01527031]), 1)),\n",
       " ((2, 48), (array([-0.08209241, -0.00280121, -0.06677457]), 1)),\n",
       " ((0, 48), (array([0.11527228, 0.14926422, 0.19360882]), 1)),\n",
       " ((0, 43), (array([0.13210141, 0.02551221, 0.11326779]), 1)),\n",
       " ((1, 43), (array([0.08943817, 0.17589097, 0.0984958 ]), 1)),\n",
       " ((1, 35), (array([0.07997747, 0.20720971, 0.13418325]), 1)),\n",
       " ((2, 35), (array([0.15660563, 0.05262887, 0.05089109]), 1)),\n",
       " ((2, 48), (array([0.17565251, 0.07263847, 0.1477747 ]), 1)),\n",
       " ((0, 48), (array([0.11201754, 0.13206191, 0.17123807]), 1)),\n",
       " ((0, 36), (array([0.10870952, 0.10778219, 0.06039915]), 1)),\n",
       " ((1, 36), (array([0.14857468, 0.0981503 , 0.14500699]), 1)),\n",
       " ((1, 22), (array([0.1206104 , 0.1803515 , 0.15356729]), 1)),\n",
       " ((2, 22), (array([0.09494779, 0.10874991, 0.10978623]), 1)),\n",
       " ((2, 48), (array([0.16520345, 0.05240134, 0.1411115 ]), 1)),\n",
       " ((0, 48), (array([0.11201754, 0.13206191, 0.17123807]), 1)),\n",
       " ((0, 36), (array([0.10870952, 0.10778219, 0.06039915]), 1)),\n",
       " ((1, 36), (array([0.14857468, 0.0981503 , 0.14500699]), 1)),\n",
       " ((1, 22), (array([0.1206104 , 0.1803515 , 0.15356729]), 1)),\n",
       " ((2, 22), (array([0.09494779, 0.10874991, 0.10978623]), 1)),\n",
       " ((2, 48), (array([0.16520345, 0.05240134, 0.1411115 ]), 1))]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hashed.flatMap(lambda x: gradient_update(x)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 29), (array([-0.18721951, -0.05344777, -0.17127541]), 4)),\n",
       " ((1, 51), (array([ 0.03103235, -0.04295678, -0.45881235]), 3)),\n",
       " ((1, 57), (array([-0.04041297,  0.01255432, -0.07420504]), 1)),\n",
       " ((1, 43), (array([0.12617871, 0.20440026, 0.11355841]), 3)),\n",
       " ((1, 77), (array([0.10455133, 0.22733912, 0.13001895]), 1)),\n",
       " ((0, 36), (array([0.16646922, 0.26998625, 0.17153074]), 5)),\n",
       " ((0, 34), (array([0.09520989, 0.14580299, 0.24223153]), 3)),\n",
       " ((1, 27), (array([0.0296366 , 0.08866191, 0.15649661]), 1)),\n",
       " ((2, 34), (array([0.14069499, 0.11453877, 0.12566669]), 3)),\n",
       " ((2, 14), (array([-0.0916813 , -0.00063737, -0.1391282 ]), 1)),\n",
       " ((1, 37), (array([0.08357662, 0.1842821 , 0.19996204]), 1)),\n",
       " ((0, 48), (array([0.31411233, 0.3417631 , 0.4107831 ]), 4)),\n",
       " ((2, 68), (array([-0.0239938 , -0.02535181,  0.01527031]), 1)),\n",
       " ((2, 48), (array([0.42396701, 0.17463993, 0.36322313]), 4)),\n",
       " ((1, 35), (array([0.07997747, 0.20720971, 0.13418325]), 1)),\n",
       " ((2, 22), (array([0.18989558, 0.21749983, 0.21957247]), 2)),\n",
       " ((0, 91), (array([-0.31664723, -0.27661176,  0.06505151]), 5)),\n",
       " ((0, 29), (array([-0.13421451, -0.12579069, -0.11934474]), 4)),\n",
       " ((2, 51), (array([-0.08149675, -0.50425155, -0.10571354]), 3)),\n",
       " ((2, 91), (array([-0.02328301, -0.05170443,  0.13804488]), 5)),\n",
       " ((2, 57), (array([-0.10559504, -0.08354991, -0.05221481]), 1)),\n",
       " ((0, 43), (array([0.1819575 , 0.0346903 , 0.17725835]), 3)),\n",
       " ((2, 77), (array([0.0872919 , 0.0326786 , 0.09099687]), 1)),\n",
       " ((1, 36), (array([0.21282483, 0.11939567, 0.15830762]), 5)),\n",
       " ((2, 27), (array([0.21497821, 0.04366709, 0.21619888]), 1)),\n",
       " ((1, 14), (array([-0.03882368, -0.11027615, -0.16983578]), 1)),\n",
       " ((2, 37), (array([0.13543866, 0.19759817, 0.19519042]), 1)),\n",
       " ((1, 68), (array([-1.38886514e-01,  1.03100416e-04,  1.18119212e-02]), 1)),\n",
       " ((2, 35), (array([0.15660563, 0.05262887, 0.05089109]), 1)),\n",
       " ((1, 22), (array([0.2412208 , 0.36070299, 0.30713459]), 2))]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hashed.flatMap(lambda x: gradient_update(x)) \\\n",
    "            .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "            .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 29), array([-0.04680488, -0.01336194, -0.04281885])),\n",
       " ((1, 51), array([ 0.01034412, -0.01431893, -0.15293745])),\n",
       " ((1, 57), array([-0.04041297,  0.01255432, -0.07420504])),\n",
       " ((1, 43), array([0.04205957, 0.06813342, 0.0378528 ])),\n",
       " ((1, 77), array([0.10455133, 0.22733912, 0.13001895])),\n",
       " ((0, 36), array([0.03329384, 0.05399725, 0.03430615])),\n",
       " ((0, 34), array([0.03173663, 0.048601  , 0.08074384])),\n",
       " ((1, 27), array([0.0296366 , 0.08866191, 0.15649661])),\n",
       " ((2, 34), array([0.04689833, 0.03817959, 0.0418889 ])),\n",
       " ((2, 14), array([-0.0916813 , -0.00063737, -0.1391282 ])),\n",
       " ((1, 37), array([0.08357662, 0.1842821 , 0.19996204])),\n",
       " ((0, 48), array([0.07852808, 0.08544077, 0.10269578])),\n",
       " ((2, 68), array([-0.0239938 , -0.02535181,  0.01527031])),\n",
       " ((2, 48), array([0.10599175, 0.04365998, 0.09080578])),\n",
       " ((1, 35), array([0.07997747, 0.20720971, 0.13418325])),\n",
       " ((2, 22), array([0.09494779, 0.10874991, 0.10978623])),\n",
       " ((0, 91), array([-0.06332945, -0.05532235,  0.0130103 ])),\n",
       " ((0, 29), array([-0.03355363, -0.03144767, -0.02983618])),\n",
       " ((2, 51), array([-0.02716558, -0.16808385, -0.03523785])),\n",
       " ((2, 91), array([-0.0046566 , -0.01034089,  0.02760898])),\n",
       " ((2, 57), array([-0.10559504, -0.08354991, -0.05221481])),\n",
       " ((0, 43), array([0.0606525 , 0.01156343, 0.05908612])),\n",
       " ((2, 77), array([0.0872919 , 0.0326786 , 0.09099687])),\n",
       " ((1, 36), array([0.04256497, 0.02387913, 0.03166152])),\n",
       " ((2, 27), array([0.21497821, 0.04366709, 0.21619888])),\n",
       " ((1, 14), array([-0.03882368, -0.11027615, -0.16983578])),\n",
       " ((2, 37), array([0.13543866, 0.19759817, 0.19519042])),\n",
       " ((1, 68), array([-1.38886514e-01,  1.03100416e-04,  1.18119212e-02])),\n",
       " ((2, 35), array([0.15660563, 0.05262887, 0.05089109])),\n",
       " ((1, 22), array([0.1206104 , 0.1803515 , 0.15356729]))]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hashed.flatMap(lambda x: gradient_update(x)) \\\n",
    "            .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "            .map(lambda x: ((x[0][0], x[0][1]), x[1][0] / x[1][1])) \\\n",
    "            .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "initial_state = np.zeros(shape=(100,3,3))\n",
    "print(initial_state)\n",
    "# sample_hashed.flatMap(lambda x: gradient_update(x)) \\\n",
    "#             .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) \\\n",
    "#             .map(lambda x: ((x[0][0], x[0][1]), x[1][0] / x[1][1])) \\\n",
    "#             .aggregateByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ffm(x, n_features, n_fields, k):\n",
    "#     G = np.ones((n_features, n_fields, k))\n",
    "    w_old = np.random(0, 1/np.sqrt(k), size=(n_features, n_fields, k))\n",
    "    sc.broadcast(w_old)\n",
    "    sc.broadcast(eta)\n",
    "#     sc.broadcast(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31617114160318766"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.random.uniform(0, 1/np.sqrt(10), size=(100, 3, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000112"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(np.random.uniform(0, 1, size=(1000000,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
