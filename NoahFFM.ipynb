{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hashlib import sha256\n",
    "\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import isnan\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set the seed\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "app_name = \"final_project_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a small sample to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sample.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile sample.txt\n",
    "1\t10\tESPN\tNike\n",
    "1\t15\tESPN\tNike\n",
    "0\t2\tESPN\tGucci\n",
    "1\t10\tESPN\tAdidas\n",
    "1\t10\tESPN\tAdidas\n",
    "0\t3\tVogue\tNike\n",
    "1\t20\tVogue\tGucci\n",
    "0\t5\tVogue\tAdidas\n",
    "1\t50\tNBC\tNike\n",
    "0\t0\tNBC\tGucci\n",
    "0\t4\tNBC\tAdidas\n",
    "0\t4\tNBC\tAdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_RDD = sc.textFile('sample.txt')\n",
    "split_RDD = sample_RDD.map(lambda line: line.split('\\t')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+------+\n",
      "| _1| _2|   _3|    _4|\n",
      "+---+---+-----+------+\n",
      "|  1| 10| ESPN|  Nike|\n",
      "|  1| 15| ESPN|  Nike|\n",
      "|  0|  2| ESPN| Gucci|\n",
      "|  1| 10| ESPN|Adidas|\n",
      "|  1| 10| ESPN|Adidas|\n",
      "|  0|  3|Vogue|  Nike|\n",
      "|  1| 20|Vogue| Gucci|\n",
      "|  0|  5|Vogue|Adidas|\n",
      "|  1| 50|  NBC|  Nike|\n",
      "|  0|  0|  NBC| Gucci|\n",
      "|  0|  4|  NBC|Adidas|\n",
      "|  0|  4|  NBC|Adidas|\n",
      "+---+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df = split_RDD.toDF()\n",
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'path file:/media/notebooks/f19-final-project-f19-team-15/data/train.parquet already exists.;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o681.save.\n: org.apache.spark.sql.AnalysisException: path file:/media/notebooks/f19-final-project-f19-team-15/data/train.parquet already exists.;\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:109)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:654)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:225)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1cae68e29bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/train.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/train.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'path file:/media/notebooks/f19-final-project-f19-team-15/data/train.parquet already exists.;'"
     ]
    }
   ],
   "source": [
    "train_data = spark.read.csv(\"data/train.txt\", sep=\"\\t\")\n",
    "train_data.write.format(\"parquet\").save(\"data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which data to load:\n",
    "# 1->sample.parquet\n",
    "# 2->smallTrain.parquet\n",
    "# 3->mediumTrain.parquet\n",
    "# 4->train.parquet (full dataset)\n",
    "\n",
    "DATA_TO_LOAD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_TO_LOAD == 1:\n",
    "    train_parquet = spark.read.parquet(f\"{PWD}/data/sample.parquet\")\n",
    "    cate_field_start = 2\n",
    "    cate_field_end = 4\n",
    "else:\n",
    "    if DATA_TO_LOAD == 2:\n",
    "        train_parquet = spark.read.parquet(f\"{PWD}/data/smallTrain.parquet\")\n",
    "    elif DATA_TO_LOAD == 3:\n",
    "        train_parquet = spark.read.parquet(f\"{PWD}/data/mediumTrain.parquet\")\n",
    "    else:\n",
    "#         train_parquet = spark.read.parquet(f\"{PWD}/data/train.parquet\")\n",
    "        train_parquet = spark.read.parquet(\"data/train.parquet\")\n",
    "    cate_field_start = 14\n",
    "    cate_field_end = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename files and recast integer types on the numeric features\n",
    "\n",
    "oldColNames = train_parquet.schema.names\n",
    "\n",
    "train_parquet = train_parquet.withColumn(\"label\", train_parquet[\"_c0\"])\n",
    "for colNum in range(1,cate_field_start): \n",
    "    colName = \"_c\" + str(colNum)\n",
    "    train_parquet = train_parquet.withColumn(\"int_feature_\"+ str(colNum), train_parquet[colName].cast(types.IntegerType()))\n",
    "for colNum in range(cate_field_start,cate_field_end): \n",
    "    colName = \"_c\" + str(colNum)\n",
    "    train_parquet = train_parquet.withColumn(\"cate_feature_\"+ str(colNum-cate_field_start+1), train_parquet[colName])\n",
    "\n",
    "#drop the old columns\n",
    "adjusted_labels_train_parquet = train_parquet.drop(*oldColNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "intFieldNames = [colName for colName, dType in adjusted_labels_train_parquet.dtypes if dType == 'int']\n",
    "cateFieldNames = [colName for colName, dType in adjusted_labels_train_parquet.dtypes if dType == 'string' and colName != 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "|label|int_feature_1|int_feature_2|int_feature_3|int_feature_4|int_feature_5|int_feature_6|int_feature_7|int_feature_8|int_feature_9|int_feature_10|int_feature_11|int_feature_12|int_feature_13|cate_feature_1|cate_feature_2|cate_feature_3|cate_feature_4|cate_feature_5|cate_feature_6|cate_feature_7|cate_feature_8|cate_feature_9|cate_feature_10|cate_feature_11|cate_feature_12|cate_feature_13|cate_feature_14|cate_feature_15|cate_feature_16|cate_feature_17|cate_feature_18|cate_feature_19|cate_feature_20|cate_feature_21|cate_feature_22|cate_feature_23|cate_feature_24|cate_feature_25|cate_feature_26|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "|    0|         null|           10|         null|            8|        10756|          173|            5|           12|           91|          null|             1|          null|             8|      05db9164|      0c0567c2|      06871b04|      a400f056|      25c83c98|      7e0ccccf|      eecf5996|      0b153874|      a73ee510|       3b08e48b|       a4cd66b8|       6f204a58|       52c47a41|       b28479f6|       e8b148e7|       02911e90|       e5ba7672|       a9cad496|           null|           null|       b85b5e46|       ad3062eb|       32c7478e|       996f5a43|           null|           null|\n",
      "|    0|         null|           -1|         null|         null|         7470|            8|           20|            0|           40|          null|             4|             0|          null|      68fd1e64|      dde11b16|      63f98b5e|      8cc7b33b|      25c83c98|      fe6b92e5|      5e64ce5f|      0b153874|      a73ee510|       88a43e6d|       4618e030|       7becd6e7|       025225f2|       b28479f6|       53c5f305|       eca39129|       e5ba7672|       43dfe9bd|           null|           null|       cf158609|           null|       32c7478e|       10b3e56d|           null|           null|\n",
      "|    0|            0|            3|            1|         null|         6593|           31|            2|            0|            1|             0|             1|          null|          null|      05db9164|      6e638bbc|      7deeba7e|      99cbea63|      43b19349|      fbad5c96|      fd28e67f|      0b153874|      a73ee510|       89ba207a|       fe5bb7d9|       e1f3056f|       6023c1d4|       051219e6|       3d5d2969|       921a13f5|       07c540c4|       3cb7e3f0|       21ddcdc9|       a458ea53|       833c4620|           null|       32c7478e|       8d653a3e|       445bbe3b|       8e1ae331|\n",
      "|    0|         null|           16|         null|         null|         2280|            8|            4|            1|            0|          null|             1|          null|          null|      9a89b36c|      8d406027|      d032c263|      c18be181|      25c83c98|      7e0ccccf|      5392de9d|      5b392875|      a73ee510|       4cd9b343|       f89fe102|       dfbb09fb|       83e6ca2e|       1adce6ef|       b65bd66b|       84898b2a|       e5ba7672|       71a94f1e|           null|           null|       0014c32a|           null|       423fab69|       3b183c5c|           null|           null|\n",
      "|    1|         null|            0|           15|            4|        40763|          950|            0|            3|          181|          null|             0|          null|             4|      05db9164|      d7988e72|      09db9d71|      139e95c0|      25c83c98|      7e0ccccf|      894562a9|      0b153874|      7cc72ec2|       7b4fbefc|       41b3f655|       dd15ab92|       ce5114a2|       051219e6|       28aed80d|       40c39996|       e5ba7672|       0f2f9850|       b304a4cc|       a458ea53|       6cfcd46a|           null|       32c7478e|       0a563957|       445bbe3b|       e81ec5ba|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adjusted_labels_train_parquet.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10\n",
    "\n",
    "train_parquet_MD = adjusted_labels_train_parquet\n",
    "\n",
    "for col in cateFieldNames:\n",
    "    valuesToKeep = adjusted_labels_train_parquet.groupBy(col).count().filter(f\"count >= {threshold}\").select(col)\n",
    "    valuesToKeep = valuesToKeep.withColumn(\"_\"+col, adjusted_labels_train_parquet[col])\n",
    "    valuesToKeep = valuesToKeep.drop(col)\n",
    "\n",
    "    train_parquet_MD = train_parquet_MD.join(F.broadcast(valuesToKeep), train_parquet_MD[col] == valuesToKeep[\"_\"+col], 'leftouter')\n",
    "    train_parquet_MD = train_parquet_MD.withColumn(col, F.when(F.col(\"_\"+col).isNull(), \"***\").otherwise(F.col(\"_\"+col)))\n",
    "    train_parquet_MD = train_parquet_MD.drop(\"_\"+col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "|label|int_feature_1|int_feature_2|int_feature_3|int_feature_4|int_feature_5|int_feature_6|int_feature_7|int_feature_8|int_feature_9|int_feature_10|int_feature_11|int_feature_12|int_feature_13|cate_feature_1|cate_feature_2|cate_feature_3|cate_feature_4|cate_feature_5|cate_feature_6|cate_feature_7|cate_feature_8|cate_feature_9|cate_feature_10|cate_feature_11|cate_feature_12|cate_feature_13|cate_feature_14|cate_feature_15|cate_feature_16|cate_feature_17|cate_feature_18|cate_feature_19|cate_feature_20|cate_feature_21|cate_feature_22|cate_feature_23|cate_feature_24|cate_feature_25|cate_feature_26|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "|    0|         null|           10|         null|            8|        10756|          173|            5|           12|           91|          null|             1|          null|             8|      05db9164|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      0b153874|      a73ee510|       3b08e48b|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|       ad3062eb|       32c7478e|            ***|            ***|            ***|\n",
      "|    0|         null|           -1|         null|         null|         7470|            8|           20|            0|           40|          null|             4|             0|          null|      68fd1e64|           ***|           ***|           ***|      25c83c98|      fe6b92e5|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|            ***|       32c7478e|            ***|            ***|            ***|\n",
      "|    0|            0|            3|            1|         null|         6593|           31|            2|            0|            1|             0|             1|          null|          null|      05db9164|           ***|           ***|           ***|      43b19349|      fbad5c96|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       07c540c4|            ***|       21ddcdc9|       a458ea53|            ***|            ***|       32c7478e|            ***|            ***|            ***|\n",
      "|    0|         null|           16|         null|         null|         2280|            8|            4|            1|            0|          null|             1|          null|          null|           ***|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      5b392875|      a73ee510|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|            ***|       423fab69|            ***|            ***|            ***|\n",
      "|    1|         null|            0|           15|            4|        40763|          950|            0|            3|          181|          null|             0|          null|             4|      05db9164|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      0b153874|           ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       e5ba7672|            ***|            ***|       a458ea53|            ***|            ***|       32c7478e|            ***|            ***|            ***|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "categorical columns processed in 16.688076972961426 seconds.\n"
     ]
    }
   ],
   "source": [
    "# view data after the replacement\n",
    "start = time.time()\n",
    "train_parquet_reduced_dimensions = train_parquet_MD\n",
    "train_parquet_reduced_dimensions.show(5)\n",
    "print(f'categorical columns processed in {time.time() - start} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in intFieldNames:\n",
    "    train_parquet_reduced_dimensions = train_parquet_reduced_dimensions.withColumn(col, F.floor(F.log(F.col(col) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "|label|int_feature_1|int_feature_2|int_feature_3|int_feature_4|int_feature_5|int_feature_6|int_feature_7|int_feature_8|int_feature_9|int_feature_10|int_feature_11|int_feature_12|int_feature_13|cate_feature_1|cate_feature_2|cate_feature_3|cate_feature_4|cate_feature_5|cate_feature_6|cate_feature_7|cate_feature_8|cate_feature_9|cate_feature_10|cate_feature_11|cate_feature_12|cate_feature_13|cate_feature_14|cate_feature_15|cate_feature_16|cate_feature_17|cate_feature_18|cate_feature_19|cate_feature_20|cate_feature_21|cate_feature_22|cate_feature_23|cate_feature_24|cate_feature_25|cate_feature_26|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "|    0|         null|            2|         null|            2|            9|            5|            1|            2|            4|          null|             0|          null|             2|      05db9164|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      0b153874|      a73ee510|       3b08e48b|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|       ad3062eb|       32c7478e|            ***|            ***|            ***|\n",
      "|    0|         null|         null|         null|         null|            8|            2|            3|            0|            3|          null|             1|             0|          null|      68fd1e64|           ***|           ***|           ***|      25c83c98|      fe6b92e5|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|            ***|       32c7478e|            ***|            ***|            ***|\n",
      "|    0|            0|            1|            0|         null|            8|            3|            1|            0|            0|             0|             0|          null|          null|      05db9164|           ***|           ***|           ***|      43b19349|      fbad5c96|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       07c540c4|            ***|       21ddcdc9|       a458ea53|            ***|            ***|       32c7478e|            ***|            ***|            ***|\n",
      "|    0|         null|            2|         null|         null|            7|            2|            1|            0|            0|          null|             0|          null|          null|           ***|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      5b392875|      a73ee510|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|            ***|       423fab69|            ***|            ***|            ***|\n",
      "|    1|         null|            0|            2|            1|           10|            6|            0|            1|            5|          null|             0|          null|             1|      05db9164|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      0b153874|           ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       e5ba7672|            ***|            ***|       a458ea53|            ***|            ***|       32c7478e|            ***|            ***|            ***|\n",
      "|    1|         null|            2|         null|            1|           11|         null|            0|            2|            1|          null|             0|          null|             1|           ***|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      0b153874|           ***|            ***|            ***|            ***|            ***|       07d13a8f|            ***|            ***|       07c540c4|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|\n",
      "|    0|         null|            4|            0|            1|            8|            3|            1|            0|            4|          null|             1|             0|             1|      05db9164|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|       a458ea53|            ***|            ***|       32c7478e|            ***|       e8b83407|            ***|\n",
      "|    0|            1|            3|            1|            1|            6|            3|            3|            3|            4|             0|             2|          null|             1|      05db9164|           ***|           ***|           ***|      25c83c98|      fbad5c96|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|\n",
      "|    0|            2|            2|            1|            2|            6|            2|            2|            2|            3|             0|             1|             0|             2|           ***|           ***|           ***|           ***|      25c83c98|      fe6b92e5|           ***|           ***|      a73ee510|       3b08e48b|            ***|            ***|            ***|       07d13a8f|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       3a171ecb|            ***|            ***|            ***|\n",
      "|    0|            0|            0|            3|            2|            5|            3|            3|            3|            5|             0|             2|             0|             3|      05db9164|           ***|           ***|           ***|      25c83c98|           ***|           ***|      0b153874|      a73ee510|       3b08e48b|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|       b1252a9d|            ***|            ***|       32c7478e|            ***|            ***|            ***|\n",
      "|    0|         null|            1|            1|            1|            7|            1|            2|            1|            2|          null|             1|          null|             1|           ***|           ***|           ***|           ***|      25c83c98|      fe6b92e5|           ***|           ***|      a73ee510|            ***|            ***|            ***|            ***|       07d13a8f|            ***|            ***|       e5ba7672|            ***|            ***|       a458ea53|            ***|       ad3062eb|       423fab69|            ***|       e8b83407|            ***|\n",
      "|    0|         null|            0|            0|            0|           10|            6|            1|            3|            5|          null|             0|          null|             0|      05db9164|           ***|           ***|           ***|      4cf72387|      7e0ccccf|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|            ***|       32c7478e|            ***|            ***|            ***|\n",
      "|    0|         null|            4|            0|            1|            9|         null|            0|            1|            3|          null|             0|          null|             1|      05db9164|           ***|           ***|           ***|      25c83c98|      fe6b92e5|           ***|      0b153874|      a73ee510|       3b08e48b|            ***|            ***|            ***|       b28479f6|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|\n",
      "|    1|            0|            3|            2|            1|            8|            2|            2|            2|            4|             0|             2|          null|             1|      05db9164|           ***|           ***|           ***|      4cf72387|      fbad5c96|           ***|           ***|      a73ee510|       3b08e48b|            ***|            ***|            ***|            ***|            ***|            ***|       e5ba7672|            ***|            ***|       a458ea53|            ***|            ***|       423fab69|            ***|            ***|            ***|\n",
      "|    0|         null|            0|            1|            0|            6|         null|            0|            0|            0|          null|             0|          null|             0|      05db9164|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      5b392875|      a73ee510|       3b08e48b|            ***|            ***|            ***|       07d13a8f|            ***|            ***|            ***|            ***|       21ddcdc9|       b1252a9d|            ***|            ***|            ***|            ***|            ***|            ***|\n",
      "|    1|            3|            0|            3|            2|            5|            2|            3|            2|            2|             0|             0|          null|             2|           ***|           ***|           ***|           ***|      25c83c98|      fbad5c96|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|       a458ea53|            ***|            ***|       3a171ecb|            ***|            ***|            ***|\n",
      "|    0|         null|            3|            1|            0|            9|            4|            4|            0|            2|          null|             1|             0|             0|      68fd1e64|           ***|           ***|           ***|      25c83c98|      fe6b92e5|           ***|           ***|      a73ee510|       3b08e48b|            ***|            ***|            ***|       07d13a8f|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       423fab69|            ***|            ***|            ***|\n",
      "|    0|         null|            5|         null|            2|            8|         null|            0|            2|            2|          null|             0|          null|             2|           ***|           ***|           ***|           ***|      43b19349|      fbad5c96|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       3a171ecb|            ***|            ***|            ***|\n",
      "|    0|            0|            0|            2|            1|            0|            1|            4|            1|            4|             0|             2|             0|             1|      68fd1e64|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      5b392875|      a73ee510|            ***|            ***|            ***|            ***|       07d13a8f|            ***|            ***|       e5ba7672|            ***|       21ddcdc9|       5840adea|            ***|       ad3062eb|       423fab69|            ***|       e8b83407|            ***|\n",
      "|    0|         null|         null|         null|         null|            7|         null|            0|            2|            2|          null|             0|          null|          null|           ***|           ***|           ***|           ***|      25c83c98|      fbad5c96|           ***|           ***|      a73ee510|       3b08e48b|            ***|            ***|            ***|       07d13a8f|            ***|            ***|            ***|            ***|            ***|            ***|            ***|            ***|       32c7478e|            ***|            ***|            ***|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "... completed job in 14.292282104492188 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_parquet_reduced_dimensions.show()\n",
    "print(f'... completed job in {time.time() - start} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100000\n",
    "n_fields = len(intFieldNames) + len(cateFieldNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher\n",
    "hasher = FeatureHasher()\n",
    "hasher.setCategoricalCols(intFieldNames)\n",
    "hasher.setNumFeatures(n_features)\n",
    "\n",
    "for col in intFieldNames + cateFieldNames:\n",
    "    hasher.setInputCols([col])\n",
    "    hasher.setOutputCol(col+\"_hashed\")\n",
    "    train_parquet_reduced_dimensions = hasher.transform(train_parquet_reduced_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+\n",
      "|label|int_feature_1|int_feature_2|int_feature_3|int_feature_4|int_feature_5|int_feature_6|int_feature_7|int_feature_8|int_feature_9|int_feature_10|int_feature_11|int_feature_12|int_feature_13|cate_feature_1|cate_feature_2|cate_feature_3|cate_feature_4|cate_feature_5|cate_feature_6|cate_feature_7|cate_feature_8|cate_feature_9|cate_feature_10|cate_feature_11|cate_feature_12|cate_feature_13|cate_feature_14|cate_feature_15|cate_feature_16|cate_feature_17|cate_feature_18|cate_feature_19|cate_feature_20|cate_feature_21|cate_feature_22|cate_feature_23|cate_feature_24|cate_feature_25|cate_feature_26|int_feature_1_hashed|int_feature_2_hashed|int_feature_3_hashed|int_feature_4_hashed|int_feature_5_hashed|int_feature_6_hashed|int_feature_7_hashed|int_feature_8_hashed|int_feature_9_hashed|int_feature_10_hashed|int_feature_11_hashed|int_feature_12_hashed|int_feature_13_hashed|cate_feature_1_hashed|cate_feature_2_hashed|cate_feature_3_hashed|cate_feature_4_hashed|cate_feature_5_hashed|cate_feature_6_hashed|cate_feature_7_hashed|cate_feature_8_hashed|cate_feature_9_hashed|cate_feature_10_hashed|cate_feature_11_hashed|cate_feature_12_hashed|cate_feature_13_hashed|cate_feature_14_hashed|cate_feature_15_hashed|cate_feature_16_hashed|cate_feature_17_hashed|cate_feature_18_hashed|cate_feature_19_hashed|cate_feature_20_hashed|cate_feature_21_hashed|cate_feature_22_hashed|cate_feature_23_hashed|cate_feature_24_hashed|cate_feature_25_hashed|cate_feature_26_hashed|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+\n",
      "|    0|         null|            2|         null|            2|            9|            5|            1|            2|            4|          null|             0|          null|             2|      05db9164|           ***|           ***|           ***|      25c83c98|      7e0ccccf|           ***|      0b153874|      a73ee510|       3b08e48b|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|       ad3062eb|       32c7478e|            ***|            ***|            ***|      (100000,[],[])|(100000,[15757],[...|      (100000,[],[])|(100000,[46777],[...|(100000,[27024],[...|(100000,[63844],[...|(100000,[93509],[...|(100000,[20980],[...|(100000,[3133],[1...|       (100000,[],[])| (100000,[28649],[...|       (100000,[],[])| (100000,[62994],[...| (100000,[38616],[...| (100000,[30186],[...| (100000,[69906],[...| (100000,[58694],[...| (100000,[84640],[...| (100000,[31272],[...| (100000,[11202],[...| (100000,[27171],[...| (100000,[86563],[...|  (100000,[43494],[...|  (100000,[37462],[...|  (100000,[87894],[...|  (100000,[68815],[...|  (100000,[11095],[...|  (100000,[67855],[...|  (100000,[97102],[...|  (100000,[46193],[...|  (100000,[12289],[...|  (100000,[72179],[...|  (100000,[75247],[...|  (100000,[36487],[...|  (100000,[10955],[...|  (100000,[49761],[...|  (100000,[84140],[...|  (100000,[31686],[...|  (100000,[77277],[...|\n",
      "|    0|         null|         null|         null|         null|            8|            2|            3|            0|            3|          null|             1|             0|          null|      68fd1e64|           ***|           ***|           ***|      25c83c98|      fe6b92e5|           ***|      0b153874|      a73ee510|            ***|            ***|            ***|            ***|       b28479f6|            ***|            ***|       e5ba7672|            ***|            ***|            ***|            ***|            ***|       32c7478e|            ***|            ***|            ***|      (100000,[],[])|      (100000,[],[])|      (100000,[],[])|      (100000,[],[])|(100000,[57993],[...|(100000,[69038],[...|(100000,[95290],[...|(100000,[23152],[...|(100000,[99130],[...|       (100000,[],[])| (100000,[25856],[...| (100000,[87498],[...|       (100000,[],[])| (100000,[27554],[...| (100000,[30186],[...| (100000,[69906],[...| (100000,[58694],[...| (100000,[84640],[...| (100000,[75660],[...| (100000,[11202],[...| (100000,[27171],[...| (100000,[86563],[...|  (100000,[75306],[...|  (100000,[37462],[...|  (100000,[87894],[...|  (100000,[68815],[...|  (100000,[11095],[...|  (100000,[67855],[...|  (100000,[97102],[...|  (100000,[46193],[...|  (100000,[12289],[...|  (100000,[72179],[...|  (100000,[75247],[...|  (100000,[36487],[...|  (100000,[32721],[...|  (100000,[49761],[...|  (100000,[84140],[...|  (100000,[31686],[...|  (100000,[77277],[...|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "... completed job in 11.714268922805786 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_parquet_reduced_dimensions.show(2)\n",
    "print(f'... completed job in {time.time() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_columns = train_parquet_reduced_dimensions.schema.names[-n_fields:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the benefit of this? Do we need to store the field value? Isn't the field value just it's index in the array anyways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a udf to parse sparse vectors\n",
    "def parse_sparse_vectors(vector, field_ind):\n",
    "    if vector.indices.size > 0:\n",
    "        return f'({field_ind},{vector.indices[0]})'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "vector_parser = F.udf(parse_sparse_vectors, types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parquet_hashed = train_parquet_reduced_dimensions\n",
    "for field_ind, col in enumerate(hashed_columns):\n",
    "    \n",
    "    train_parquet_hashed = train_parquet_hashed.withColumn(col, vector_parser(col, F.lit(field_ind)))\n",
    "\n",
    "train_parquet_hashed = train_parquet_hashed.drop(*(intFieldNames + cateFieldNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+\n",
      "|label|int_feature_1_hashed|int_feature_2_hashed|int_feature_3_hashed|int_feature_4_hashed|int_feature_5_hashed|int_feature_6_hashed|int_feature_7_hashed|int_feature_8_hashed|int_feature_9_hashed|int_feature_10_hashed|int_feature_11_hashed|int_feature_12_hashed|int_feature_13_hashed|cate_feature_1_hashed|cate_feature_2_hashed|cate_feature_3_hashed|cate_feature_4_hashed|cate_feature_5_hashed|cate_feature_6_hashed|cate_feature_7_hashed|cate_feature_8_hashed|cate_feature_9_hashed|cate_feature_10_hashed|cate_feature_11_hashed|cate_feature_12_hashed|cate_feature_13_hashed|cate_feature_14_hashed|cate_feature_15_hashed|cate_feature_16_hashed|cate_feature_17_hashed|cate_feature_18_hashed|cate_feature_19_hashed|cate_feature_20_hashed|cate_feature_21_hashed|cate_feature_22_hashed|cate_feature_23_hashed|cate_feature_24_hashed|cate_feature_25_hashed|cate_feature_26_hashed|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+\n",
      "|    0|                null|           (1,15757)|                null|           (3,46777)|           (4,27024)|           (5,63844)|           (6,93509)|           (7,20980)|            (8,3133)|                 null|           (10,28649)|                 null|           (12,62994)|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,31272)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,43494)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,11095)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,10955)|            (35,49761)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|                null|                null|                null|                null|           (4,57993)|           (5,69038)|           (6,95290)|           (7,23152)|           (8,99130)|                 null|           (10,25856)|           (11,87498)|                 null|           (13,27554)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,75660)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,11095)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,49761)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|           (0,52838)|           (1,89867)|           (2,83977)|                null|           (4,57993)|           (5,21606)|           (6,93509)|           (7,23152)|           (8,39301)|            (9,70853)|           (10,28649)|                 null|                 null|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,34387)|           (18,50746)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,74968)|            (27,67855)|            (28,97102)|            (29,53602)|            (30,12289)|            (31,50618)|             (32,7149)|            (33,36487)|            (34,32721)|            (35,49761)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|                null|           (1,15757)|                null|                null|           (4,45339)|           (5,69038)|           (6,93509)|           (7,23152)|           (8,39301)|                 null|           (10,28649)|                 null|                 null|           (13,64192)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,31272)|           (19,11202)|           (20,82336)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,74968)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,90270)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    1|                null|            (1,4408)|            (2,3014)|             (3,679)|           (4,40717)|           (5,29117)|           (6,42737)|           (7,10669)|           (8,99916)|                 null|           (10,28649)|                 null|           (12,52881)|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,31272)|           (19,11202)|           (20,27171)|           (21,93367)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,74968)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|             (32,7149)|            (33,36487)|            (34,32721)|            (35,49761)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    1|                null|           (1,15757)|                null|             (3,679)|           (4,11705)|                null|           (6,42737)|           (7,20980)|           (8,81135)|                 null|           (10,28649)|                 null|           (12,52881)|           (13,64192)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,31272)|           (19,11202)|           (20,27171)|           (21,93367)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,33612)|            (27,67855)|            (28,97102)|            (29,53602)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,68011)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|                null|           (1,92336)|           (2,83977)|             (3,679)|           (4,57993)|           (5,21606)|           (6,93509)|           (7,23152)|            (8,3133)|                 null|           (10,25856)|           (11,87498)|           (12,52881)|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,31272)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,11095)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|             (32,7149)|            (33,36487)|            (34,32721)|            (35,49761)|            (36,84140)|             (37,6937)|            (38,77277)|\n",
      "|    0|           (0,83715)|           (1,99858)|           (2,36554)|             (3,679)|           (4,85256)|           (5,21606)|           (6,95290)|           (7,59529)|            (8,3133)|            (9,70853)|           (10,77967)|                 null|           (12,52881)|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,50746)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,74968)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,68011)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|           (0,37515)|           (1,15757)|           (2,36554)|           (3,46777)|           (4,85256)|           (5,69038)|           (6,87940)|           (7,20980)|           (8,99130)|            (9,70853)|           (10,25856)|           (11,87498)|           (12,62994)|           (13,64192)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,75660)|           (19,11202)|           (20,93961)|           (21,86563)|            (22,43494)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,33612)|            (27,67855)|            (28,97102)|            (29,10325)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,42773)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|           (0,52838)|            (1,4408)|           (2,69573)|           (3,46777)|           (4,74028)|           (5,21606)|           (6,95290)|           (7,59529)|           (8,99916)|            (9,70853)|           (10,77967)|           (11,87498)|            (12,9629)|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,23340)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,43494)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,11095)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|            (32,82434)|            (33,36487)|            (34,32721)|            (35,49761)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|                null|           (1,89867)|           (2,36554)|             (3,679)|           (4,45339)|           (5,19017)|           (6,87940)|           (7,10669)|           (8,47212)|                 null|           (10,25856)|                 null|           (12,52881)|           (13,64192)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,75660)|           (19,11202)|           (20,93961)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,33612)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|             (32,7149)|            (33,36487)|            (34,10955)|            (35,90270)|            (36,84140)|             (37,6937)|            (38,77277)|\n",
      "|    0|                null|            (1,4408)|           (2,83977)|           (3,46475)|           (4,40717)|           (5,29117)|           (6,93509)|           (7,59529)|           (8,99916)|                 null|           (10,28649)|                 null|           (12,72498)|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,25021)|           (18,31272)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,11095)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,49761)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|                null|           (1,92336)|           (2,83977)|             (3,679)|           (4,27024)|                null|           (6,42737)|           (7,10669)|           (8,99130)|                 null|           (10,28649)|                 null|           (12,52881)|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,75660)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,43494)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,11095)|            (27,67855)|            (28,97102)|            (29,10325)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,68011)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    1|           (0,52838)|           (1,99858)|            (2,3014)|             (3,679)|           (4,57993)|           (5,69038)|           (6,87940)|           (7,20980)|            (8,3133)|            (9,70853)|           (10,77967)|                 null|           (12,52881)|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,25021)|           (18,50746)|           (19,11202)|           (20,93961)|           (21,86563)|            (22,43494)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,74968)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|             (32,7149)|            (33,36487)|            (34,32721)|            (35,90270)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|                null|            (1,4408)|           (2,36554)|           (3,46475)|           (4,85256)|                null|           (6,42737)|           (7,23152)|           (8,39301)|                 null|           (10,28649)|                 null|           (12,72498)|           (13,38616)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,31272)|           (19,11202)|           (20,82336)|           (21,86563)|            (22,43494)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,33612)|            (27,67855)|            (28,97102)|            (29,10325)|            (30,12289)|            (31,50618)|            (32,82434)|            (33,36487)|            (34,32721)|            (35,68011)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    1|           (0,12079)|            (1,4408)|           (2,69573)|           (3,46777)|           (4,74028)|           (5,69038)|           (6,95290)|           (7,20980)|           (8,47212)|            (9,70853)|           (10,28649)|                 null|           (12,62994)|           (13,64192)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,50746)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,11095)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,72179)|             (32,7149)|            (33,36487)|            (34,32721)|            (35,42773)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|                null|           (1,99858)|           (2,36554)|           (3,46475)|           (4,27024)|           (5,35276)|           (6,57211)|           (7,23152)|           (8,47212)|                 null|           (10,25856)|           (11,87498)|           (12,72498)|           (13,27554)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,75660)|           (19,11202)|           (20,93961)|           (21,86563)|            (22,43494)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,33612)|            (27,67855)|            (28,97102)|            (29,10325)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,90270)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|                null|           (1,40243)|                null|           (3,46777)|           (4,57993)|                null|           (6,42737)|           (7,20980)|           (8,47212)|                 null|           (10,28649)|                 null|           (12,62994)|           (13,64192)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,34387)|           (18,50746)|           (19,11202)|           (20,27171)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,74968)|            (27,67855)|            (28,97102)|            (29,10325)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,42773)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "|    0|           (0,52838)|            (1,4408)|            (2,3014)|             (3,679)|           (4,95509)|           (5,19017)|           (6,57211)|           (7,10669)|            (8,3133)|            (9,70853)|           (10,77967)|           (11,87498)|           (12,52881)|           (13,27554)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,31272)|           (19,11202)|           (20,82336)|           (21,86563)|            (22,75306)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,33612)|            (27,67855)|            (28,97102)|            (29,46193)|            (30,12289)|            (31,50618)|            (32,97451)|            (33,36487)|            (34,10955)|            (35,90270)|            (36,84140)|             (37,6937)|            (38,77277)|\n",
      "|    0|                null|                null|                null|                null|           (4,45339)|                null|           (6,42737)|           (7,20980)|           (8,47212)|                 null|           (10,28649)|                 null|                 null|           (13,64192)|           (14,30186)|           (15,69906)|           (16,58694)|           (17,84640)|           (18,50746)|           (19,11202)|           (20,93961)|           (21,86563)|            (22,43494)|            (23,37462)|            (24,87894)|            (25,68815)|            (26,33612)|            (27,67855)|            (28,97102)|            (29,10325)|            (30,12289)|            (31,72179)|            (32,75247)|            (33,36487)|            (34,32721)|            (35,49761)|            (36,84140)|            (37,31686)|            (38,77277)|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "... completed job in 6.666346311569214 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_parquet_hashed.show()\n",
    "print(f'... completed job in {time.time() - start} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redefining the train_parquet\n",
    "I'm not saving the hashed value as a field-hashed_value tuple because is the field not known from when the array is looped over in the RDD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sparse_vectors(vector, field_ind):\n",
    "    if vector.indices.size > 0:\n",
    "        return int(vector.indices[0])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "vector_parser = F.udf(parse_sparse_vectors, types.IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parquet_hashed = train_parquet_reduced_dimensions\n",
    "for field_ind, col in enumerate(hashed_columns):\n",
    "    \n",
    "    train_parquet_hashed = train_parquet_hashed.withColumn(col, vector_parser(col, F.lit(field_ind)))\n",
    "\n",
    "train_parquet_hashed = train_parquet_hashed.drop(*(intFieldNames + cateFieldNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+\n",
      "|label|int_feature_1_hashed|int_feature_2_hashed|int_feature_3_hashed|int_feature_4_hashed|int_feature_5_hashed|int_feature_6_hashed|int_feature_7_hashed|int_feature_8_hashed|int_feature_9_hashed|int_feature_10_hashed|int_feature_11_hashed|int_feature_12_hashed|int_feature_13_hashed|cate_feature_1_hashed|cate_feature_2_hashed|cate_feature_3_hashed|cate_feature_4_hashed|cate_feature_5_hashed|cate_feature_6_hashed|cate_feature_7_hashed|cate_feature_8_hashed|cate_feature_9_hashed|cate_feature_10_hashed|cate_feature_11_hashed|cate_feature_12_hashed|cate_feature_13_hashed|cate_feature_14_hashed|cate_feature_15_hashed|cate_feature_16_hashed|cate_feature_17_hashed|cate_feature_18_hashed|cate_feature_19_hashed|cate_feature_20_hashed|cate_feature_21_hashed|cate_feature_22_hashed|cate_feature_23_hashed|cate_feature_24_hashed|cate_feature_25_hashed|cate_feature_26_hashed|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+\n",
      "|    0|                null|               15757|                null|               46777|               27024|               63844|               93509|               20980|                3133|                 null|                28649|                 null|                62994|                38616|                30186|                69906|                58694|                84640|                31272|                11202|                27171|                86563|                 43494|                 37462|                 87894|                 68815|                 11095|                 67855|                 97102|                 46193|                 12289|                 72179|                 75247|                 36487|                 10955|                 49761|                 84140|                 31686|                 77277|\n",
      "|    0|                null|                null|                null|                null|               57993|               69038|               95290|               23152|               99130|                 null|                25856|                87498|                 null|                27554|                30186|                69906|                58694|                84640|                75660|                11202|                27171|                86563|                 75306|                 37462|                 87894|                 68815|                 11095|                 67855|                 97102|                 46193|                 12289|                 72179|                 75247|                 36487|                 32721|                 49761|                 84140|                 31686|                 77277|\n",
      "|    0|               52838|               89867|               83977|                null|               57993|               21606|               93509|               23152|               39301|                70853|                28649|                 null|                 null|                38616|                30186|                69906|                58694|                34387|                50746|                11202|                27171|                86563|                 75306|                 37462|                 87894|                 68815|                 74968|                 67855|                 97102|                 53602|                 12289|                 50618|                  7149|                 36487|                 32721|                 49761|                 84140|                 31686|                 77277|\n",
      "|    0|                null|               15757|                null|                null|               45339|               69038|               93509|               23152|               39301|                 null|                28649|                 null|                 null|                64192|                30186|                69906|                58694|                84640|                31272|                11202|                82336|                86563|                 75306|                 37462|                 87894|                 68815|                 74968|                 67855|                 97102|                 46193|                 12289|                 72179|                 75247|                 36487|                 32721|                 90270|                 84140|                 31686|                 77277|\n",
      "|    1|                null|                4408|                3014|                 679|               40717|               29117|               42737|               10669|               99916|                 null|                28649|                 null|                52881|                38616|                30186|                69906|                58694|                84640|                31272|                11202|                27171|                93367|                 75306|                 37462|                 87894|                 68815|                 74968|                 67855|                 97102|                 46193|                 12289|                 72179|                  7149|                 36487|                 32721|                 49761|                 84140|                 31686|                 77277|\n",
      "|    1|                null|               15757|                null|                 679|               11705|                null|               42737|               20980|               81135|                 null|                28649|                 null|                52881|                64192|                30186|                69906|                58694|                84640|                31272|                11202|                27171|                93367|                 75306|                 37462|                 87894|                 68815|                 33612|                 67855|                 97102|                 53602|                 12289|                 72179|                 75247|                 36487|                 32721|                 68011|                 84140|                 31686|                 77277|\n",
      "|    0|                null|               92336|               83977|                 679|               57993|               21606|               93509|               23152|                3133|                 null|                25856|                87498|                52881|                38616|                30186|                69906|                58694|                84640|                31272|                11202|                27171|                86563|                 75306|                 37462|                 87894|                 68815|                 11095|                 67855|                 97102|                 46193|                 12289|                 72179|                  7149|                 36487|                 32721|                 49761|                 84140|                  6937|                 77277|\n",
      "|    0|               83715|               99858|               36554|                 679|               85256|               21606|               95290|               59529|                3133|                70853|                77967|                 null|                52881|                38616|                30186|                69906|                58694|                84640|                50746|                11202|                27171|                86563|                 75306|                 37462|                 87894|                 68815|                 74968|                 67855|                 97102|                 46193|                 12289|                 72179|                 75247|                 36487|                 32721|                 68011|                 84140|                 31686|                 77277|\n",
      "|    0|               37515|               15757|               36554|               46777|               85256|               69038|               87940|               20980|               99130|                70853|                25856|                87498|                62994|                64192|                30186|                69906|                58694|                84640|                75660|                11202|                93961|                86563|                 43494|                 37462|                 87894|                 68815|                 33612|                 67855|                 97102|                 10325|                 12289|                 72179|                 75247|                 36487|                 32721|                 42773|                 84140|                 31686|                 77277|\n",
      "|    0|               52838|                4408|               69573|               46777|               74028|               21606|               95290|               59529|               99916|                70853|                77967|                87498|                 9629|                38616|                30186|                69906|                58694|                84640|                23340|                11202|                27171|                86563|                 43494|                 37462|                 87894|                 68815|                 11095|                 67855|                 97102|                 46193|                 12289|                 72179|                 82434|                 36487|                 32721|                 49761|                 84140|                 31686|                 77277|\n",
      "|    0|                null|               89867|               36554|                 679|               45339|               19017|               87940|               10669|               47212|                 null|                25856|                 null|                52881|                64192|                30186|                69906|                58694|                84640|                75660|                11202|                93961|                86563|                 75306|                 37462|                 87894|                 68815|                 33612|                 67855|                 97102|                 46193|                 12289|                 72179|                  7149|                 36487|                 10955|                 90270|                 84140|                  6937|                 77277|\n",
      "|    0|                null|                4408|               83977|               46475|               40717|               29117|               93509|               59529|               99916|                 null|                28649|                 null|                72498|                38616|                30186|                69906|                58694|                25021|                31272|                11202|                27171|                86563|                 75306|                 37462|                 87894|                 68815|                 11095|                 67855|                 97102|                 46193|                 12289|                 72179|                 75247|                 36487|                 32721|                 49761|                 84140|                 31686|                 77277|\n",
      "|    0|                null|               92336|               83977|                 679|               27024|                null|               42737|               10669|               99130|                 null|                28649|                 null|                52881|                38616|                30186|                69906|                58694|                84640|                75660|                11202|                27171|                86563|                 43494|                 37462|                 87894|                 68815|                 11095|                 67855|                 97102|                 10325|                 12289|                 72179|                 75247|                 36487|                 32721|                 68011|                 84140|                 31686|                 77277|\n",
      "|    1|               52838|               99858|                3014|                 679|               57993|               69038|               87940|               20980|                3133|                70853|                77967|                 null|                52881|                38616|                30186|                69906|                58694|                25021|                50746|                11202|                93961|                86563|                 43494|                 37462|                 87894|                 68815|                 74968|                 67855|                 97102|                 46193|                 12289|                 72179|                  7149|                 36487|                 32721|                 90270|                 84140|                 31686|                 77277|\n",
      "|    0|                null|                4408|               36554|               46475|               85256|                null|               42737|               23152|               39301|                 null|                28649|                 null|                72498|                38616|                30186|                69906|                58694|                84640|                31272|                11202|                82336|                86563|                 43494|                 37462|                 87894|                 68815|                 33612|                 67855|                 97102|                 10325|                 12289|                 50618|                 82434|                 36487|                 32721|                 68011|                 84140|                 31686|                 77277|\n",
      "|    1|               12079|                4408|               69573|               46777|               74028|               69038|               95290|               20980|               47212|                70853|                28649|                 null|                62994|                64192|                30186|                69906|                58694|                84640|                50746|                11202|                27171|                86563|                 75306|                 37462|                 87894|                 68815|                 11095|                 67855|                 97102|                 46193|                 12289|                 72179|                  7149|                 36487|                 32721|                 42773|                 84140|                 31686|                 77277|\n",
      "|    0|                null|               99858|               36554|               46475|               27024|               35276|               57211|               23152|               47212|                 null|                25856|                87498|                72498|                27554|                30186|                69906|                58694|                84640|                75660|                11202|                93961|                86563|                 43494|                 37462|                 87894|                 68815|                 33612|                 67855|                 97102|                 10325|                 12289|                 72179|                 75247|                 36487|                 32721|                 90270|                 84140|                 31686|                 77277|\n",
      "|    0|                null|               40243|                null|               46777|               57993|                null|               42737|               20980|               47212|                 null|                28649|                 null|                62994|                64192|                30186|                69906|                58694|                34387|                50746|                11202|                27171|                86563|                 75306|                 37462|                 87894|                 68815|                 74968|                 67855|                 97102|                 10325|                 12289|                 72179|                 75247|                 36487|                 32721|                 42773|                 84140|                 31686|                 77277|\n",
      "|    0|               52838|                4408|                3014|                 679|               95509|               19017|               57211|               10669|                3133|                70853|                77967|                87498|                52881|                27554|                30186|                69906|                58694|                84640|                31272|                11202|                82336|                86563|                 75306|                 37462|                 87894|                 68815|                 33612|                 67855|                 97102|                 46193|                 12289|                 50618|                 97451|                 36487|                 10955|                 90270|                 84140|                  6937|                 77277|\n",
      "|    0|                null|                null|                null|                null|               45339|                null|               42737|               20980|               47212|                 null|                28649|                 null|                 null|                64192|                30186|                69906|                58694|                84640|                50746|                11202|                93961|                86563|                 43494|                 37462|                 87894|                 68815|                 33612|                 67855|                 97102|                 10325|                 12289|                 72179|                 75247|                 36487|                 32721|                 49761|                 84140|                 31686|                 77277|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "... completed job in 9.596228837966919 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_parquet_hashed.show()\n",
    "print(f'... completed job in {time.time() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change labels to be -1 and 1\n",
    "train_parquet_hashed = train_parquet_hashed.withColumn(\"label\", F.when(F.col(\"label\") == 0, -1).otherwise(F.col(\"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label='-1', int_feature_1_hashed=None, int_feature_2_hashed=15757, int_feature_3_hashed=None, int_feature_4_hashed=46777, int_feature_5_hashed=27024, int_feature_6_hashed=63844, int_feature_7_hashed=93509, int_feature_8_hashed=20980, int_feature_9_hashed=3133, int_feature_10_hashed=None, int_feature_11_hashed=28649, int_feature_12_hashed=None, int_feature_13_hashed=62994, cate_feature_1_hashed=38616, cate_feature_2_hashed=30186, cate_feature_3_hashed=69906, cate_feature_4_hashed=58694, cate_feature_5_hashed=84640, cate_feature_6_hashed=31272, cate_feature_7_hashed=11202, cate_feature_8_hashed=27171, cate_feature_9_hashed=86563, cate_feature_10_hashed=43494, cate_feature_11_hashed=37462, cate_feature_12_hashed=87894, cate_feature_13_hashed=68815, cate_feature_14_hashed=11095, cate_feature_15_hashed=67855, cate_feature_16_hashed=97102, cate_feature_17_hashed=46193, cate_feature_18_hashed=12289, cate_feature_19_hashed=72179, cate_feature_20_hashed=75247, cate_feature_21_hashed=36487, cate_feature_22_hashed=10955, cate_feature_23_hashed=49761, cate_feature_24_hashed=84140, cate_feature_25_hashed=31686, cate_feature_26_hashed=77277)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parquet_hashed.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_features(x):\n",
    "    row = x.split('\\t')\n",
    "    row[0] = int(row[0])\n",
    "    for i in range(1, 14):\n",
    "        try:\n",
    "            row[i] = int(row[i])\n",
    "        except ValueError:\n",
    "            row[i] = 0\n",
    "#     for i in range(14, 14 + 26):\n",
    "#         try:\n",
    "#             row[i] = int(row[i], base=16)\n",
    "#         except ValueError:\n",
    "#             row[i] = 0\n",
    "    return row[:14]\n",
    "\n",
    "def feature_hash(x, modulo=10**6):\n",
    "    \"\"\"\n",
    "    A function that can be used to hash the features in each observation in the RDD. \n",
    "    We replace the label with 1, -1 and we hash all other features using sha256 \n",
    "    and then we take modulo some power of 10. \n",
    "    \"\"\"\n",
    "\n",
    "    x[0] = 2*int(x[0]) - 1\n",
    "    for i, value in enumerate(x[1:], 1):\n",
    "        h = sha256(\"{i}-{val}\".format(i=i,val=value).encode('ascii'))\n",
    "        hashed_value = int(h.hexdigest(), base=16) \n",
    "        hashed_value_mod = hashed_value % modulo\n",
    "        x[i] = hashed_value_mod\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_hashed = split_RDD.map(lambda x: feature_hash(x, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 16, 4],\n",
       " [1, 7, 16, 4],\n",
       " [-1, 2, 16, 18],\n",
       " [1, 1, 16, 11],\n",
       " [1, 1, 16, 11],\n",
       " [-1, 2, 9, 4],\n",
       " [1, 14, 9, 18],\n",
       " [-1, 12, 9, 11],\n",
       " [1, 18, 23, 4],\n",
       " [-1, 10, 23, 18],\n",
       " [-1, 22, 23, 11],\n",
       " [-1, 22, 23, 11]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hashed.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFM\n",
    "Mathematically, FMM can be expressed as:\n",
    "\n",
    "$ \\phi_{FFM}(w, x) = \\sum\\limits^{n}_{j_1=1} \\sum\\limits^{n}_{j_2=j_1+1}(w_{j_1} \\cdot w_{j_2})x_{j_1}x_{j_2}$\n",
    "\n",
    "However, in the models considered, either all variables are categorical or all integer values are binned effectively making them categorical and the $x_{j_1}$ and $x_{j_2}$ are both equal to 1. This reduces the formula to:\n",
    "\n",
    "$ \\phi_{FFM}(w, x) = \\sum\\limits^{n}_{j_1=1} \\sum\\limits^{n}_{j_2=j_1+1}(w_{j_1} \\cdot w_{j_2})$\n",
    "\n",
    "The optimization function considered for this model is log loss with regularization and the following formula is to be minimized.\n",
    "\n",
    "$\\underset{w}{min}$   $\\dfrac{\\lambda}{2}||w||_2^2 + \\sum\\limits^{m}_{i=1}log(1 + exp(-y_i\\phi_{FFM}(w,x_i)))$\n",
    "\n",
    "Currently, a closed-form solution for minimizing log loss is not known and therefore gradient descent is applied. The gradients for $\\phi_{FFM}(w, x)$ are:\n",
    "\n",
    "$g_{j_1,f_2} = \\triangledown_{w_{j_1,f_2}} f(w) = \\lambda \\cdot w_{j_1,f_2} + \\kappa \\cdot w_{j_2,f_1}$\n",
    "\n",
    "$g_{j_2,f_1} = \\triangledown_{w_{j_2,f_1}} f(w) = \\lambda \\cdot w_{j_2,f_1} + \\kappa \\cdot w_{j_1,f_2}$\n",
    "\n",
    "where,\n",
    "\n",
    "$\\kappa = \\dfrac{\\partial log(1 + exp(-y\\phi_{FFM}(w,x)))}{\\partial \\phi_{FFM}(w, x)} = \\dfrac{-y}{1 + exp(y\\phi_{FFM}(w,x))}$\n",
    "\n",
    "Initially we define two helper function for $\\phi_{FFM}$ and $\\kappa$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x):\n",
    "    return np.sum([np.dot(W[x[i], j, :], W[x[j], i, :]) for i in range(len(x) - 1) for j in range(i + 1, len(x))])\n",
    "\n",
    "def kappa(y, features):\n",
    "    return -y/(1 + np.exp(y*phi(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = sample_hashed.take(1)\n",
    "# W = np.random.uniform(0, 1/np.sqrt(3), size=(25, 3, 3))\n",
    "# sc.broadcast(W)\n",
    "# wj0f1_wj1f0 = np.dot(W[1, 1, :], W[16, 0, :])\n",
    "# wj0f2_wj2f0 = np.dot(W[1, 2, :], W[4, 0, :])\n",
    "# wj1f2_wj2f1 = np.dot(W[16, 2, :], W[4, 1, :])\n",
    "# total = wj0f1_wj1f0 + wj0f2_wj2f0 + wj1f2_wj2f1\n",
    "# print(f\"Expected value is the sum of these three: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "This initial model is simply FFM with gradient descent without the regularization term in the optimization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label='0', int_feature_1_hashed=None, int_feature_2_hashed='15757', int_feature_3_hashed=None, int_feature_4_hashed='46777', int_feature_5_hashed='27024', int_feature_6_hashed='63844', int_feature_7_hashed='93509', int_feature_8_hashed='20980', int_feature_9_hashed='3133', int_feature_10_hashed=None, int_feature_11_hashed='28649', int_feature_12_hashed=None, int_feature_13_hashed='62994', cate_feature_1_hashed='38616', cate_feature_2_hashed='30186', cate_feature_3_hashed='69906', cate_feature_4_hashed='58694', cate_feature_5_hashed='84640', cate_feature_6_hashed='31272', cate_feature_7_hashed='11202', cate_feature_8_hashed='27171', cate_feature_9_hashed='86563', cate_feature_10_hashed='43494', cate_feature_11_hashed='37462', cate_feature_12_hashed='87894', cate_feature_13_hashed='68815', cate_feature_14_hashed='11095', cate_feature_15_hashed='67855', cate_feature_16_hashed='97102', cate_feature_17_hashed='46193', cate_feature_18_hashed='12289', cate_feature_19_hashed='72179', cate_feature_20_hashed='75247', cate_feature_21_hashed='36487', cate_feature_22_hashed='10955', cate_feature_23_hashed='49761', cate_feature_24_hashed='84140', cate_feature_25_hashed='31686', cate_feature_26_hashed='77277')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parquet_hashed.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_parquet_hashed.rdd.take(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "k = 10\n",
    "n_features = 100\n",
    "n_fields = 3\n",
    "eta = 0.4\n",
    "reg_c = 0.1\n",
    "sc.broadcast(k)\n",
    "sc.broadcast(n_features)\n",
    "sc.broadcast(n_fields)\n",
    "sc.broadcast(reg_c)\n",
    "sc.broadcast(eta)\n",
    "\n",
    "# initialize \n",
    "W = np.random.uniform(0, 1/np.sqrt(k), size=(n_features, n_fields, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x):\n",
    "    y = int(x[0])\n",
    "    features = x[1:]\n",
    "    kap = kappa(y, features)\n",
    "    \n",
    "    gradients = np.zeros(shape=(n_features, n_fields, k))\n",
    "    \n",
    "    for i in range(len(features) - 1):\n",
    "        for j in range(i+1, len(features)):\n",
    "            gradients[features[i], j] += kap * W[features[j], i, :] #+ reg_c * W[features[i], j, :]\n",
    "            gradients[features[j], i] += kap * W[features[i], j, :] #+ reg_c * W[features[j], i, :]\n",
    "            \n",
    "    return gradients\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(dataRDD, W):\n",
    "    return dataRDD.map(lambda x: np.log(1 + np.exp(-x[0] * phi(x[1:])))).mean()\n",
    "\n",
    "def gd_update(dataRDD, W):\n",
    "    grad = dataRDD.map(lambda x: gradient(x)).mean()\n",
    "    \n",
    "    new_model = W - eta * grad\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "STEP: 1\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 758.0 failed 1 times, most recent failure: Lost task 0.0 in stage 758.0 (TID 68082, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 370, in func\n    return f(iterator)\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 1083, in <lambda>\n    return self.mapPartitions(lambda i: [StatCounter(i)]).reduce(redFunc)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/statcounter.py\", line 42, in __init__\n    for v in values:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-18-cb4890ae5284>\", line 5, in <lambda>\n  File \"<ipython-input-22-eb920899843b>\", line 4, in gradient\n  File \"<ipython-input-15-040dec60766d>\", line 5, in kappa\nTypeError: bad operand type for unary -: 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:162)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor47.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 370, in func\n    return f(iterator)\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 1083, in <lambda>\n    return self.mapPartitions(lambda i: [StatCounter(i)]).reduce(redFunc)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/statcounter.py\", line 42, in __init__\n    for v in values:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-18-cb4890ae5284>\", line 5, in <lambda>\n  File \"<ipython-input-22-eb920899843b>\", line 4, in gradient\n  File \"<ipython-input-15-040dec60766d>\", line 5, in kappa\nTypeError: bad operand type for unary -: 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-201b5d096c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"STEP: {i+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_rdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_rdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss: {loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-cb4890ae5284>\u001b[0m in \u001b[0;36mgd_update\u001b[0;34m(dataRDD, W)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataRDD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \"\"\"\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mstats\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mleft_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmergeStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStatCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m         \"\"\"\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 758.0 failed 1 times, most recent failure: Lost task 0.0 in stage 758.0 (TID 68082, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 370, in func\n    return f(iterator)\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 1083, in <lambda>\n    return self.mapPartitions(lambda i: [StatCounter(i)]).reduce(redFunc)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/statcounter.py\", line 42, in __init__\n    for v in values:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-18-cb4890ae5284>\", line 5, in <lambda>\n  File \"<ipython-input-22-eb920899843b>\", line 4, in gradient\n  File \"<ipython-input-15-040dec60766d>\", line 5, in kappa\nTypeError: bad operand type for unary -: 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:938)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:162)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor47.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 2457, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 370, in func\n    return f(iterator)\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 1083, in <lambda>\n    return self.mapPartitions(lambda i: [StatCounter(i)]).reduce(redFunc)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/statcounter.py\", line 42, in __init__\n    for v in values:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-18-cb4890ae5284>\", line 5, in <lambda>\n  File \"<ipython-input-22-eb920899843b>\", line 4, in gradient\n  File \"<ipython-input-15-040dec60766d>\", line 5, in kappa\nTypeError: bad operand type for unary -: 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(RDD.scala:939)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "train_rdd = train_parquet_hashed.rdd\n",
    "n_steps = 10\n",
    "for i in range(n_steps):\n",
    "    print(\"----------\")\n",
    "    print(f\"STEP: {i+1}\")\n",
    "    W = gd_update(train_rdd, W)\n",
    "    loss = log_loss(train_rdd, W)\n",
    "    print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "STEP: 1\n",
      "Loss: 0.6229139305285584\n",
      "----------\n",
      "STEP: 2\n",
      "Loss: 0.6130204900696186\n",
      "----------\n",
      "STEP: 3\n",
      "Loss: 0.6034141452853868\n",
      "----------\n",
      "STEP: 4\n",
      "Loss: 0.5940629962744435\n",
      "----------\n",
      "STEP: 5\n",
      "Loss: 0.5849350752906279\n",
      "----------\n",
      "STEP: 6\n",
      "Loss: 0.5759985032221872\n",
      "----------\n",
      "STEP: 7\n",
      "Loss: 0.5672216149085344\n",
      "----------\n",
      "STEP: 8\n",
      "Loss: 0.5585730527947136\n",
      "----------\n",
      "STEP: 9\n",
      "Loss: 0.5500218298331966\n",
      "----------\n",
      "STEP: 10\n",
      "Loss: 0.5415373636675113\n"
     ]
    }
   ],
   "source": [
    "def gradient(x):\n",
    "    y = x[0]\n",
    "    features = x[1:]\n",
    "    kap = kappa(y, features)\n",
    "    \n",
    "    gradients = np.zeros(shape=(n_features, n_fields, k))\n",
    "    \n",
    "    for i in range(len(features) - 1):\n",
    "        for j in range(i+1, len(features)):\n",
    "            gradients[features[i], j] += kap * W[features[j], i, :] + reg_c * W[features[i], j, :]\n",
    "            gradients[features[j], i] += kap * W[features[i], j, :] + reg_c * W[features[j], i, :]\n",
    "            \n",
    "    return gradients\n",
    "\n",
    "n_steps = 10\n",
    "for i in range(n_steps):\n",
    "    print(\"----------\")\n",
    "    print(f\"STEP: {i+1}\")\n",
    "    W = gd_update(sample_hashed, W)\n",
    "    loss = log_loss(sample_hashed, W)\n",
    "    print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = spark.read.csv(\"sample.txt\", sep=\"\\t\")\n",
    "sample_data.write.format(\"parquet\").save(\"sample.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = spark.read.parquet(\"sample.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+------+\n",
      "|_c0|_c1|  _c2|   _c3|\n",
      "+---+---+-----+------+\n",
      "|  1| 10| ESPN|  Nike|\n",
      "|  1| 15| ESPN|  Nike|\n",
      "|  0|  2| ESPN| Gucci|\n",
      "|  1| 10| ESPN|Adidas|\n",
      "|  1| 10| ESPN|Adidas|\n",
      "|  0|  3|Vogue|  Nike|\n",
      "|  1| 20|Vogue| Gucci|\n",
      "|  0|  5|Vogue|Adidas|\n",
      "|  1| 50|  NBC|  Nike|\n",
      "|  0|  0|  NBC| Gucci|\n",
      "|  0|  4|  NBC|Adidas|\n",
      "|  0|  4|  NBC|Adidas|\n",
      "+---+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<b'_c0'>\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "col should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ca73a63cdadf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# from pyspark.sql.functions import col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# sample_df.select(*(feature_hash(col(c)).alias(c) for c in sample_df.columns)).show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msample_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_c0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_c0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \"\"\"\n\u001b[0;32m-> 1848\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: col should be Column"
     ]
    }
   ],
   "source": [
    "def feature_hash(x, modulo=10**6):\n",
    "    \"\"\"\n",
    "    A function that can be used to hash the features in each observation in the RDD. \n",
    "    We replace the label with 1, -1 and we hash all other features using sha256 \n",
    "    and then we take modulo some power of 10. \n",
    "    \"\"\"\n",
    "    print(x)\n",
    "#     x[0] = 2*int(x[0]) - 1\n",
    "#     for i, value in enumerate(x[1:], 1):\n",
    "#         h = sha256(\"{i}-{val}\".format(i=i,val=value).encode('ascii'))\n",
    "#         hashed_value = int(h.hexdigest(), base=16) \n",
    "#         hashed_value_mod = hashed_value % modulo\n",
    "#         x[i] = hashed_value_mod\n",
    "#     return x\n",
    "\n",
    "# from pyspark.sql.functions import col\n",
    "# sample_df.select(*(feature_hash(col(c)).alias(c) for c in sample_df.columns)).show()\n",
    "sample_df.withColumn(\"_c0\", feature_hash(sample_df[\"_c0\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Full Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.read.csv(\"data/dac/train.txt\", sep=\"\\t\")\n",
    "train_data.write.format(\"parquet\").save(f\"data/dac/train.parquet\")\n",
    "full_rdd = sc.textFile('data/dac/train.txt')\n",
    "train_rdd, test_rdd = full_rdd.randomSplit([0.8,0.2], seed = 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parquet = spark.read.parquet(\"data/dac/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "oldColNames = train_parquet.schema.names\n",
    "train_parquet = train_parquet.withColumn(\"label\", train_parquet[\"_c0\"])\n",
    "for colNum in range(1,14): \n",
    "    colName = \"_c\" + str(colNum)\n",
    "    train_parquet = train_parquet.withColumn(\"int_feature_\"+ str(colNum), train_parquet[colName].cast(types.IntegerType()))\n",
    "for colNum in range(14,40): \n",
    "    colName = \"_c\" + str(colNum)\n",
    "    train_parquet = train_parquet.withColumn(\"cate_feature_\"+ str(colNum-13), train_parquet[colName])\n",
    "\n",
    "#drop the old columns\n",
    "train_parquet = train_parquet.drop(*oldColNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100\n",
    "n_fields = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "intFieldNames = [colName for colName, dType in train_parquet.dtypes if dType == 'int']\n",
    "cateFieldNames = [colName for colName, dType in train_parquet.dtypes if dType == 'string' and colName != 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher\n",
    "hasher = FeatureHasher()\n",
    "hasher.setCategoricalCols(intFieldNames)\n",
    "hasher.setNumFeatures(n_features)\n",
    "\n",
    "# for col in intFieldNames + cateFieldNames:\n",
    "hasher.setInputCols(intFieldNames + cateFieldNames)\n",
    "hasher.setOutputCol(\"hashed_features\")\n",
    "train_parquet = hasher.transform(train_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+--------------------+\n",
      "|label|int_feature_1|int_feature_2|int_feature_3|int_feature_4|int_feature_5|int_feature_6|int_feature_7|int_feature_8|int_feature_9|int_feature_10|int_feature_11|int_feature_12|int_feature_13|cate_feature_1|cate_feature_2|cate_feature_3|cate_feature_4|cate_feature_5|cate_feature_6|cate_feature_7|cate_feature_8|cate_feature_9|cate_feature_10|cate_feature_11|cate_feature_12|cate_feature_13|cate_feature_14|cate_feature_15|cate_feature_16|cate_feature_17|cate_feature_18|cate_feature_19|cate_feature_20|cate_feature_21|cate_feature_22|cate_feature_23|cate_feature_24|cate_feature_25|cate_feature_26|     hashed_features|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+--------------------+\n",
      "|    0|         null|          139|         null|            2|         4828|           28|           11|            2|           28|          null|             1|             0|             2|      05db9164|      d833535f|      77f2f2e5|      d16679b9|      4cf72387|      fe6b92e5|      9ea2e0f0|      0b153874|      a73ee510|       43b7a3fa|       2dad6ba2|       9f32b866|       47cb697a|       07d13a8f|       943169c2|       31ca40b6|       e5ba7672|       281769c2|           null|           null|       dfcfc3fa|       c9d4222a|       32c7478e|       aee52b6f|           null|           null|(100,[12,13,16,19...|\n",
      "+-----+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+-------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+--------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+---------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_parquet.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2531.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.next(SparkPlan.scala:282)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.next(SparkPlan.scala:276)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.foreach(SparkPlan.scala:276)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeCollect$1.apply(SparkPlan.scala:298)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeCollect$1.apply(SparkPlan.scala:297)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:297)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3195)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3192)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3253)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3192)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-a7dfc3150655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_parquet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int_feature_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \"\"\"\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2531.collectToPython.\n: java.lang.OutOfMemoryError: Java heap space\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.next(SparkPlan.scala:282)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.next(SparkPlan.scala:276)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.sql.execution.SparkPlan$$anon$1.foreach(SparkPlan.scala:276)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeCollect$1.apply(SparkPlan.scala:298)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeCollect$1.apply(SparkPlan.scala:297)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:297)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3195)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3192)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3254)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3253)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3192)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "train_parquet.select(\"int_feature_1\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cate_feature_1',\n",
       " 'cate_feature_2',\n",
       " 'cate_feature_3',\n",
       " 'cate_feature_4',\n",
       " 'cate_feature_5',\n",
       " 'cate_feature_6',\n",
       " 'cate_feature_7',\n",
       " 'cate_feature_8',\n",
       " 'cate_feature_9',\n",
       " 'cate_feature_10',\n",
       " 'cate_feature_11',\n",
       " 'cate_feature_12',\n",
       " 'cate_feature_13',\n",
       " 'cate_feature_14',\n",
       " 'cate_feature_15',\n",
       " 'cate_feature_16',\n",
       " 'cate_feature_17',\n",
       " 'cate_feature_18',\n",
       " 'cate_feature_19',\n",
       " 'cate_feature_20',\n",
       " 'cate_feature_21',\n",
       " 'cate_feature_22',\n",
       " 'cate_feature_23',\n",
       " 'cate_feature_24',\n",
       " 'cate_feature_25',\n",
       " 'cate_feature_26']"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in intFieldNames + cateFieldNames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2599.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2599.0 (TID 5158, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 1371, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-309-ecdd36739116>\", line 1, in <lambda>\n  File \"<ipython-input-6-601d2890c953>\", line 8, in feature_hash\nTypeError: 'str' object does not support item assignment\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 1371, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-309-ecdd36739116>\", line 1, in <lambda>\n  File \"<ipython-input-6-601d2890c953>\", line 8, in feature_hash\nTypeError: 'str' object does not support item assignment\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-309-ecdd36739116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_hashed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_rdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeature_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_hashed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/py4j-0.10.7-py3.6.egg/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2599.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2599.0 (TID 5158, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 1371, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-309-ecdd36739116>\", line 1, in <lambda>\n  File \"<ipython-input-6-601d2890c953>\", line 8, in feature_hash\nTypeError: 'str' object does not support item assignment\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1602)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1590)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1589)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1589)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1823)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1772)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1761)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor296.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 230, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 225, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/rdd.py\", line 1371, in takeUpToNumLeft\n    yield next(iterator)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 55, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-309-ecdd36739116>\", line 1, in <lambda>\n  File \"<ipython-input-6-601d2890c953>\", line 8, in feature_hash\nTypeError: 'str' object does not support item assignment\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "sample_hashed = train_rdd.map(lambda x: feature_hash(x, 100000))\n",
    "sample_hashed.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment\n",
    "We then consider how well the model is performing on the training vs test set to check if the model is tending to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 16, 4]]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hashed.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 16), (1, 41), (16, 41)]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "list(itertools.combinations([1, 16, 41], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value is the sum of these three: 0.7879988184229724\n"
     ]
    }
   ],
   "source": [
    "wj0f1_wj1f0 = np.dot(W[1, 1, :], W[16, 0, :])\n",
    "wj0f2_wj2f0 = np.dot(W[1, 2, :], W[4, 0, :])\n",
    "wj1f2_wj2f1 = np.dot(W[16, 2, :], W[4, 1, :])\n",
    "total = wj0f1_wj1f0 + wj0f2_wj2f0 + wj1f2_wj2f1\n",
    "print(f\"Expected value is the sum of these three: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7879988184229724"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hashed.map(lambda x: phi(x[1:])).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000112"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(np.random.uniform(0,1,size=(10000000,10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras to consider\n",
    "## Develop classes for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FFM:\n",
    "#     def __init__(self, n_features, k = 10, eta = 0.1, reg_c = 0.1):\n",
    "#         self.n_features = n_features\n",
    "#         self.k = k\n",
    "#         self.eta = eta\n",
    "#         self.reg_c = reg_c\n",
    "        \n",
    "        \n",
    "# ffm = FFM(25, k=3)\n",
    "# ffm.n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- We develop the paper this way to mimic homework from throughout the semester and build the model up sequentially\n",
    "- Should we write tests and show them in the presentation for simple function like $\\phi_{FFM}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
